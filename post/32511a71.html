<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"timewait7.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":true,"preload":true}}</script><script src="/js/config.js"></script>

    <meta name="description" content="MySQL查询当OFFSET值很大时（如LIMIT 100000, 10），为什么查询会变慢 原因：MySQL需先扫描并跳过offset + limit行，再返回结果。  优化方案：  使用索引覆盖扫描： 123SELECT * FROM orders WHERE id &gt;&#x3D; (SELECT id FROM orders ORDER BY id LIMIT 100000, 1)ORDER B">
<meta property="og:type" content="article">
<meta property="og:title" content="学习&amp;面试-数据存储">
<meta property="og:url" content="http://timewait7.github.io/post/32511a71.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="MySQL查询当OFFSET值很大时（如LIMIT 100000, 10），为什么查询会变慢 原因：MySQL需先扫描并跳过offset + limit行，再返回结果。  优化方案：  使用索引覆盖扫描： 123SELECT * FROM orders WHERE id &gt;&#x3D; (SELECT id FROM orders ORDER BY id LIMIT 100000, 1)ORDER B">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://timewait7.github.io/post/32511a71/1726212535664-4bb3f3ff-704a-4706-84c8-a046a8486657.webp">
<meta property="og:image" content="https://cdn.tobebetterjavaer.com/stutymore/redis-20240918114125.png">
<meta property="og:image" content="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/redis-b7b24e25-d2dc-4457-994f-95bdb3674b8e.png">
<meta property="og:image" content="http://timewait7.github.io/post/32511a71/image-20250807221917345.png">
<meta property="article:published_time" content="2025-07-26T11:19:32.000Z">
<meta property="article:modified_time" content="2025-08-09T02:09:29.250Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://timewait7.github.io/post/32511a71/1726212535664-4bb3f3ff-704a-4706-84c8-a046a8486657.webp">


<link rel="canonical" href="http://timewait7.github.io/post/32511a71.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://timewait7.github.io/post/32511a71.html","path":"post/32511a71.html","title":"学习&面试-数据存储"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>学习&面试-数据存储 | Hexo</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hexo</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-archives"><a href="/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#MySQL"><span class="nav-number">1.</span> <span class="nav-text">MySQL</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2"><span class="nav-number">1.1.</span> <span class="nav-text">查询</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BD%93OFFSET%E5%80%BC%E5%BE%88%E5%A4%A7%E6%97%B6%EF%BC%88%E5%A6%82LIMIT-100000-10%EF%BC%89%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9F%A5%E8%AF%A2%E4%BC%9A%E5%8F%98%E6%85%A2"><span class="nav-number">1.1.1.</span> <span class="nav-text">当OFFSET值很大时（如LIMIT 100000, 10），为什么查询会变慢</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E9%A1%B5%E6%97%B6%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BF%85%E9%A1%BB%E6%90%AD%E9%85%8DORDER-BY"><span class="nav-number">1.1.2.</span> <span class="nav-text">分页时为什么必须搭配ORDER BY</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%B4%A2%E5%BC%95"><span class="nav-number">1.2.</span> <span class="nav-text">索引</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E7%B1%BB%E5%9E%8B%E7%B4%A2%E5%BC%95"><span class="nav-number">1.2.1.</span> <span class="nav-text">都有哪些类型索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%9E%E8%A1%A8%E3%80%81%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95%E3%80%81%E6%9C%80%E5%B7%A6%E5%89%8D%E7%BC%80%E5%8E%9F%E5%88%99%E5%92%8C%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8"><span class="nav-number">1.2.2.</span> <span class="nav-text">什么是回表、覆盖索引、最左前缀原则和索引下推</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#InnoDB%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84"><span class="nav-number">1.2.3.</span> <span class="nav-text">InnoDB索引结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88MongoDB%E4%BD%BF%E7%94%A8B%E6%A0%91%E8%80%8CMySQL%E7%94%A8B-%E6%A0%91"><span class="nav-number">1.2.4.</span> <span class="nav-text">为什么MongoDB使用B树而MySQL用B+树</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B4%A2%E5%BC%95%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99"><span class="nav-number">1.2.5.</span> <span class="nav-text">索引设计原则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%97%B6%E7%B4%A2%E5%BC%95%E4%BC%9A%E5%A4%B1%E6%95%88%E6%88%96%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95"><span class="nav-number">1.2.6.</span> <span class="nav-text">为什么有时索引会失效或选错索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%84%E5%90%88%E7%B4%A2%E5%BC%95-a-b-c-%E5%9C%A8%E6%9F%A5%E8%AF%A2-WHERE-b-1-AND-c-2-ORDER-BY-a-%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5"><span class="nav-number">1.2.7.</span> <span class="nav-text">组合索引 (a, b, c) 在查询 WHERE b&#x3D;1 AND c&#x3D;2 ORDER BY a 中的使用情况</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%85%A2%E6%9F%A5%E8%AF%A2"><span class="nav-number">1.3.</span> <span class="nav-text">慢查询</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%85%A2SQL%E4%BC%98%E5%8C%96%E5%85%A8%E6%B5%81%E7%A8%8B"><span class="nav-number">1.3.1.</span> <span class="nav-text">慢SQL优化全流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%97%B6%E5%8F%AA%E6%9F%A5%E8%AF%A2%E4%B8%80%E8%A1%8C%E4%BD%86%E6%98%AF%E5%BE%88%E6%85%A2"><span class="nav-number">1.3.2.</span> <span class="nav-text">为什么有时只查询一行但是很慢</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8B%E5%8A%A1"><span class="nav-number">1.4.</span> <span class="nav-text">事务</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E5%92%8C%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB"><span class="nav-number">1.4.1.</span> <span class="nav-text">事务的基本特性和隔离级别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MVCC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="nav-number">1.4.2.</span> <span class="nav-text">MVCC实现原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E9%97%B4%E9%9A%99%E9%94%81%E5%92%8C%E4%B8%B4%E9%94%AE%E9%94%81"><span class="nav-number">1.4.3.</span> <span class="nav-text">什么是间隙锁和临键锁</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4"><span class="nav-number">1.4.4.</span> <span class="nav-text">什么是两阶段提交</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8"><span class="nav-number">1.5.</span> <span class="nav-text">分库分表</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8"><span class="nav-number">1.5.1.</span> <span class="nav-text">什么是分库分表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E6%8B%86%E5%88%86%E7%BB%B4%E5%BA%A6"><span class="nav-number">1.5.2.</span> <span class="nav-text">常见拆分维度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%8C%91%E6%88%98"><span class="nav-number">1.5.3.</span> <span class="nav-text">分库分表带来的挑战</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%A4%A7%E7%9A%84%E6%95%B0%E6%8D%AE%E9%87%8F%E9%9C%80%E8%A6%81%E8%80%83%E8%99%91%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8"><span class="nav-number">1.5.4.</span> <span class="nav-text">多大的数据量需要考虑分库分表</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96"><span class="nav-number">1.6.</span> <span class="nav-text">其他</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#char-100-%E5%92%8C-varchar-100-%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">1.6.1.</span> <span class="nav-text">char(100) 和 varchar(100) 的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%BB%BA%E8%AE%AE%E4%BD%BF%E7%94%A8-text-%E4%BD%9C%E4%B8%BA%E5%AD%97%E6%AE%B5%E7%B1%BB%E5%9E%8B"><span class="nav-number">1.6.2.</span> <span class="nav-text">为什么不建议使用 text 作为字段类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F"><span class="nav-number">1.6.3.</span> <span class="nav-text">查询语句的执行顺序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E6%9D%A1%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="nav-number">1.6.4.</span> <span class="nav-text">一条查询语句的执行流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E6%9D%A1%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B"><span class="nav-number">1.6.5.</span> <span class="nav-text">一条更新语句的执行过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#EXPLAIN-%E5%AD%97%E6%AE%B5%E8%AF%B4%E6%98%8E"><span class="nav-number">1.6.6.</span> <span class="nav-text">EXPLAIN 字段说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88InnoDB%E4%B8%8D%E4%BF%9D%E5%AD%98%E8%A1%A8%E7%9A%84%E6%80%BB%E8%A1%8C%E6%95%B0"><span class="nav-number">1.6.7.</span> <span class="nav-text">为什么InnoDB不保存表的总行数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#count-%E3%80%81count-1-%E3%80%81count-id-%E3%80%81count-%E5%AD%97%E6%AE%B5-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB"><span class="nav-number">1.6.8.</span> <span class="nav-text">count(*)、count(1)、count(id)、count(字段)有什么区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#InnoDB%E5%92%8CMyISAM%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">1.6.9.</span> <span class="nav-text">InnoDB和MyISAM的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%BB%BA%E8%AE%AE%E4%BD%BF%E7%94%A8text%E7%B1%BB%E5%9E%8B"><span class="nav-number">1.6.10.</span> <span class="nav-text">为什么不建议使用text类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redo-log%E3%80%81binlog%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB"><span class="nav-number">1.6.11.</span> <span class="nav-text">redo log、binlog有什么区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%B7%E7%9B%98"><span class="nav-number">1.6.12.</span> <span class="nav-text">什么是刷盘</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#buffer-pool%E5%92%8Cchange-buffer%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB"><span class="nav-number">1.6.13.</span> <span class="nav-text">buffer pool和change buffer有什么区别</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Redis"><span class="nav-number">2.</span> <span class="nav-text">Redis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="nav-number">2.1.</span> <span class="nav-text">数据结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-%E6%9C%89%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%EF%BC%8C%E5%88%86%E5%88%AB%E7%94%A8%E4%BA%8E%E5%93%AA%E4%BA%9B%E5%9C%BA%E6%99%AF"><span class="nav-number">2.1.1.</span> <span class="nav-text">Redis 有哪些数据类型，分别用于哪些场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BF%AB%EF%BC%9F%E5%8D%95%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E9%AB%98%E5%B9%B6%E5%8F%91%EF%BC%9F"><span class="nav-number">2.1.2.</span> <span class="nav-text">Redis为什么快？单线程如何处理高并发？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis%E5%92%8CMySQL%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">2.1.3.</span> <span class="nav-text">Redis和MySQL的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis%E5%92%8Cmemchahed%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">2.1.4.</span> <span class="nav-text">Redis和memchahed的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8"><span class="nav-number">2.1.5.</span> <span class="nav-text">Redis IO多路复用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-6-0-%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="nav-number">2.1.6.</span> <span class="nav-text">Redis 6.0 多线程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="nav-number">2.2.</span> <span class="nav-text">内存管理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#IO%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.3.</span> <span class="nav-text">IO模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%AD%98"><span class="nav-number">2.4.</span> <span class="nav-text">缓存</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-%E9%9B%AA%E5%B4%A9-%E5%87%BB%E7%A9%BF%EF%BC%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">2.4.1.</span> <span class="nav-text">什么是缓存穿透&#x2F;雪崩&#x2F;击穿，对应的解决方案是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="nav-number">2.4.2.</span> <span class="nav-text">布隆过滤器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5"><span class="nav-number">2.4.3.</span> <span class="nav-text">缓存淘汰策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5"><span class="nav-number">2.4.4.</span> <span class="nav-text">缓存与数据的更新策略</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-number">2.5.</span> <span class="nav-text">持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RDB%E5%92%8CAOF%E6%8C%81%E4%B9%85%E5%8C%96%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8A%A3%E5%AF%B9%E6%AF%94"><span class="nav-number">2.5.1.</span> <span class="nav-text">RDB和AOF持久化原理及优劣对比</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E9%87%8F%E5%90%8C%E6%AD%A5%E5%92%8C%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">2.5.2.</span> <span class="nav-text">全量同步和增量同步的区别</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="nav-number">2.6.</span> <span class="nav-text">分布式锁</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.6.1.</span> <span class="nav-text">Redis分布式锁实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E8%AF%AF%E9%87%8A%E6%94%BE%E9%94%81"><span class="nav-number">2.6.2.</span> <span class="nav-text">如何避免误释放锁</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%94%81%E7%BB%AD%E6%9C%9F"><span class="nav-number">2.6.3.</span> <span class="nav-text">如何实现锁续期</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4"><span class="nav-number">2.7.</span> <span class="nav-text">集群</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%A8-Redis-%E4%B8%AD%E7%BB%91%E5%AE%9A-CPU-%E6%A0%B8"><span class="nav-number">2.7.1.</span> <span class="nav-text">在 Redis 中绑定 CPU 核</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ElasticSearch"><span class="nav-number">3.</span> <span class="nav-text">ElasticSearch</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Elasticsearch-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="nav-number">3.1.</span> <span class="nav-text">Elasticsearch 的核心概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%E5%AE%83%E5%AF%B9%E6%90%9C%E7%B4%A2%E5%BE%88%E9%87%8D%E8%A6%81%EF%BC%9F"><span class="nav-number">3.2.</span> <span class="nav-text">什么是倒排索引？为什么它对搜索很重要？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E7%89%87%EF%BC%88Shard%EF%BC%89%E5%92%8C%E5%89%AF%E6%9C%AC%EF%BC%88Replica%EF%BC%89%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">3.3.</span> <span class="nav-text">分片（Shard）和副本（Replica）是什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Elasticsearch-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%EF%BC%9F"><span class="nav-number">3.4.</span> <span class="nav-text">Elasticsearch 如何保证写入数据的可靠性？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A%E4%B8%80%E4%B8%8B-Elasticsearch-%E4%B8%AD%E7%9A%84-refresh-%E5%92%8C-flush-%E6%93%8D%E4%BD%9C%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">3.5.</span> <span class="nav-text">解释一下 Elasticsearch 中的 refresh 和 flush 操作的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E7%8A%B6%E6%80%81-Yellow-%E6%88%96-Red-%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88%EF%BC%9F%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5"><span class="nav-number">3.6.</span> <span class="nav-text">集群状态 Yellow 或 Red 意味着什么？如何排查?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A%E4%B8%80%E4%B8%8B%E4%BB%80%E4%B9%88%E6%98%AF%E8%84%91%E8%A3%82%EF%BC%88Split-Brain%EF%BC%89%E9%97%AE%E9%A2%98%EF%BC%9FElasticsearch-%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E8%84%91%E8%A3%82%EF%BC%9F"><span class="nav-number">3.7.</span> <span class="nav-text">解释一下什么是脑裂（Split-Brain）问题？Elasticsearch 如何防止脑裂？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%98%A0%E5%B0%84%E7%88%86%E7%82%B8%EF%BC%9F%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%EF%BC%9F"><span class="nav-number">3.8.</span> <span class="nav-text">什么是映射爆炸？如何避免？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B%E4%BD%A0%E4%BC%9A%E8%80%83%E8%99%91%E4%BD%BF%E7%94%A8-keyword-%E7%B1%BB%E5%9E%8B%E8%80%8C%E4%B8%8D%E6%98%AF-text-%E7%B1%BB%E5%9E%8B%EF%BC%9F"><span class="nav-number">3.9.</span> <span class="nav-text">什么情况下你会考虑使用 keyword 类型而不是 text 类型？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E6%AE%B5%E5%90%88%E5%B9%B6%EF%BC%88Segment-Merging%EF%BC%89%EF%BC%9F%E5%AE%83%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="nav-number">3.10.</span> <span class="nav-text">为什么需要段合并（Segment Merging）？它有什么优缺点？</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/">
          <span class="site-state-item-count">28</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://timewait7.github.io/post/32511a71.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="学习&面试-数据存储 | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          学习&面试-数据存储
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-07-26 19:19:32" itemprop="dateCreated datePublished" datetime="2025-07-26T19:19:32+08:00">2025-07-26</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>22k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1:22</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><h3 id="当OFFSET值很大时（如LIMIT-100000-10），为什么查询会变慢"><a href="#当OFFSET值很大时（如LIMIT-100000-10），为什么查询会变慢" class="headerlink" title="当OFFSET值很大时（如LIMIT 100000, 10），为什么查询会变慢"></a>当<code>OFFSET</code>值很大时（如<code>LIMIT 100000, 10</code>），为什么查询会变慢</h3><ul>
<li><p><strong>原因</strong>：MySQL需先扫描并跳过<code>offset + limit</code>行，再返回结果。</p>
</li>
<li><p><strong>优化方案</strong>：</p>
<ol>
<li><p><strong>使用索引覆盖扫描</strong>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> orders </span><br><span class="line"><span class="keyword">WHERE</span> id <span class="operator">&gt;=</span> (<span class="keyword">SELECT</span> id <span class="keyword">FROM</span> orders <span class="keyword">ORDER</span> <span class="keyword">BY</span> id LIMIT <span class="number">100000</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id LIMIT <span class="number">10</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>记录上一页最后一条数据的ID</strong>（推荐）：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> orders </span><br><span class="line"><span class="keyword">WHERE</span> id <span class="operator">&gt;</span> last_seen_id  <span class="comment">-- 上一页最后一条记录的ID</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id LIMIT <span class="number">10</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>子查询</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> </span><br><span class="line"><span class="keyword">FROM</span> orders </span><br><span class="line"><span class="keyword">WHERE</span> id <span class="operator">&gt;=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> id <span class="keyword">FROM</span> orders <span class="keyword">ORDER</span> <span class="keyword">BY</span> id LIMIT <span class="number">10000</span>, <span class="number">1</span></span><br><span class="line">) </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id </span><br><span class="line">LIMIT <span class="number">10</span>;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<h3 id="分页时为什么必须搭配ORDER-BY"><a href="#分页时为什么必须搭配ORDER-BY" class="headerlink" title="分页时为什么必须搭配ORDER BY"></a>分页时为什么必须搭配<code>ORDER BY</code></h3><ul>
<li><p>缺少<code>ORDER BY</code>时，MySQL返回结果的顺序不确定（可能因索引、存储引擎变化），导致分页结果混乱。</p>
</li>
<li><p><strong>正确写法</strong>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> products <span class="keyword">ORDER</span> <span class="keyword">BY</span> price <span class="keyword">DESC</span> LIMIT <span class="number">0</span>, <span class="number">10</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="都有哪些类型索引"><a href="#都有哪些类型索引" class="headerlink" title="都有哪些类型索引"></a>都有哪些类型索引</h3><h3 id="什么是回表、覆盖索引、最左前缀原则和索引下推"><a href="#什么是回表、覆盖索引、最左前缀原则和索引下推" class="headerlink" title="什么是回表、覆盖索引、最左前缀原则和索引下推"></a>什么是回表、覆盖索引、最左前缀原则和索引下推</h3><p><strong>回表</strong>：查询需要的字段没有全部包含在索引中，需要根据索引找到主键，再从主键索引中找到完整数据才能获取所需字段。</p>
<p><strong>覆盖索引</strong>：查询所需的字段都包含在索引中，无需回表操作。</p>
<p><strong>最左前缀原则</strong>：复合索引 <code>(a, b, c)</code> 的查询条件必须从最左列开始，且不能跳过中间列才能命中索引。</p>
<h3 id="InnoDB索引结构"><a href="#InnoDB索引结构" class="headerlink" title="InnoDB索引结构"></a>InnoDB索引结构</h3><p>B树结构</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">       [10 | 20]</span><br><span class="line">      /    |     \</span><br><span class="line">[5|8]  [12|15|18]  [25|30]</span><br></pre></td></tr></table></figure>

<p>特征：</p>
<ul>
<li>所有节点都存储完整数据</li>
<li>每个节点最多包涵 m-1 个键值和 m 个子节点</li>
</ul>
<p>B+树结构</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">               [15]</span><br><span class="line">              /    \</span><br><span class="line">     [10|15]          [20|25]</span><br><span class="line">     /     \          /     \ </span><br><span class="line">[10|...]→[15|...]→[20|...]→[25|...]（叶子节点链表）</span><br></pre></td></tr></table></figure>

<p>特征：</p>
<ul>
<li>只有叶子节点存储完整数据，内部节点只存储索引</li>
<li>叶子节点通过双向链表连接，支持高效范围查询</li>
<li>相同磁盘页可以存储更多索引，提高查询效率</li>
</ul>
<p><strong>InnoDB选择B+树的7大关键原因</strong></p>
<table>
<thead>
<tr>
<th align="left"><strong>对比维度</strong></th>
<th align="left"><strong>B树</strong></th>
<th align="left"><strong>B+树</strong></th>
<th align="left"><strong>InnoDB优势体现</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>数据存储位置</strong></td>
<td align="left">所有节点存储数据</td>
<td align="left">仅叶子节点存储数据</td>
<td align="left">减少磁盘IO次数</td>
</tr>
<tr>
<td align="left"><strong>树高度</strong></td>
<td align="left">较高（数据分散存储）</td>
<td align="left">较低（内部节点纯索引）</td>
<td align="left">3层B+树可支撑千万级数据</td>
</tr>
<tr>
<td align="left"><strong>范围查询</strong></td>
<td align="left">需要回溯父节点</td>
<td align="left">通过叶子链表顺序扫描</td>
<td align="left"><code>WHERE id &gt; 100</code> 效率提升10倍+</td>
</tr>
<tr>
<td align="left"><strong>全表扫描</strong></td>
<td align="left">需遍历整棵树</td>
<td align="left">直接顺序遍历叶子节点链表</td>
<td align="left">全表扫描速度接近顺序读</td>
</tr>
<tr>
<td align="left"><strong>磁盘利用率</strong></td>
<td align="left">节点包含数据导致存储键值数少</td>
<td align="left">单页可存储更多键值（高分支因子）</td>
<td align="left">相同数据量减少30%-50%树高度</td>
</tr>
<tr>
<td align="left"><strong>数据更新代价</strong></td>
<td align="left">可能引起复杂结构调整</td>
<td align="left">插入删除多数情况只需局部调整</td>
<td align="left">支持更高并发写入</td>
</tr>
<tr>
<td align="left"><strong>缓存命中率</strong></td>
<td align="left">热点数据分散在不同层级</td>
<td align="left">叶子节点集中存储所有数据</td>
<td align="left">Buffer Pool利用率提升40%+</td>
</tr>
</tbody></table>
<h3 id="为什么MongoDB使用B树而MySQL用B-树"><a href="#为什么MongoDB使用B树而MySQL用B-树" class="headerlink" title="为什么MongoDB使用B树而MySQL用B+树"></a>为什么MongoDB使用B树而MySQL用B+树</h3><p>MongoDB面向文档存储，需快速获取整个文档（B树的内部节点存储完整数据，可以减少寻址次数）</p>
<p>MySQL侧重范围查询和事务处理（B+树的顺序访问特性更优秀）</p>
<h3 id="索引设计原则"><a href="#索引设计原则" class="headerlink" title="索引设计原则"></a>索引设计原则</h3><ul>
<li>前缀索引优化</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="keyword">user</span> <span class="keyword">ADD</span> INDEX (name(<span class="number">10</span>));</span><br></pre></td></tr></table></figure>

<ul>
<li>覆盖索引优化</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建包含所有查询字段的索引</span></span><br><span class="line"><span class="keyword">CREATE</span> INDEX idx_cover <span class="keyword">ON</span> orders(user_id, status, create_time);</span><br></pre></td></tr></table></figure>

<h3 id="为什么有时索引会失效或选错索引"><a href="#为什么有时索引会失效或选错索引" class="headerlink" title="为什么有时索引会失效或选错索引"></a>为什么有时索引会失效或选错索引</h3><p>索引失效的常见场景：</p>
<ul>
<li>违反最左前缀原则</li>
<li>对索引列进行运算或函数操作</li>
<li>使用 <code>or</code> 连接非索引列</li>
<li>索引列存在大量重复值，如性别</li>
<li>使用 <code>like &#39;%地址&#39;</code></li>
</ul>
<p>选错索引的常见原因：</p>
<ul>
<li><p>统计信息不准确：优化器依赖的统计信息（如 <code>cardinality</code>）过时，误判索引效率。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 表数据分布已变化，但统计信息未更新</span><br><span class="line">ANALYZE TABLE users; -- 手动更新统计信息</span><br></pre></td></tr></table></figure>
</li>
<li><p>索引覆盖不足：索引未覆盖查询所需字段，导致回表成本过高。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 索引 (a) 无法覆盖 SELECT *</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="operator">=</span> <span class="number">1</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 使用覆盖索引</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="keyword">table</span> <span class="keyword">ADD</span> INDEX idx_a_b_c (a, b, c);</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="组合索引-a-b-c-在查询-WHERE-b-1-AND-c-2-ORDER-BY-a-中的使用情况"><a href="#组合索引-a-b-c-在查询-WHERE-b-1-AND-c-2-ORDER-BY-a-中的使用情况" class="headerlink" title="组合索引 (a, b, c) 在查询 WHERE b=1 AND c=2 ORDER BY a 中的使用情况"></a>组合索引 <code>(a, b, c)</code> 在查询 <code>WHERE b=1 AND c=2 ORDER BY a</code> 中的使用情况</h3><p><strong>WHERE 条件 (<code>b=1 AND c=2</code>)</strong></p>
<ul>
<li>由于缺少最左列 <code>a</code>，无法直接使用索引的<strong>快速查找</strong>（B+Tree 的有序性在跳过 <code>a</code> 后失效）。</li>
<li>但优化器可能选择 <strong>全索引扫描 (Full Index Scan)</strong> 或 <strong>索引范围扫描</strong>：<ul>
<li>遍历整个索引 <code>(a, b, c)</code> 的叶子节点。</li>
<li>逐行检查 <code>b=1 AND c=2</code> 的条件（类似全表扫描，但扫描的是索引而非数据行）。</li>
</ul>
</li>
</ul>
<p><strong>ORDER BY a</strong></p>
<ul>
<li>✅ <strong>索引天然按 <code>a</code> 排序</strong>：<br>组合索引 <code>(a, b, c)</code> 本身按 <code>a</code> 升序排列（若 <code>a</code> 相同，再按 <code>b</code>、<code>c</code> 排）。<br>→ 因此 <code>ORDER BY a</code> <strong>可直接利用索引顺序，避免额外的排序操作</strong>（避免 <code>Filesort</code>）。</li>
</ul>
<p><strong>索引覆盖 (Covering Index)</strong></p>
<ul>
<li>如果查询的列<strong>全部包含在索引中</strong>（如 <code>SELECT a, b, c</code>），则：<br>✅ 引擎只需扫描索引，<strong>无需回表</strong>查数据行（更快）。</li>
</ul>
<h2 id="慢查询"><a href="#慢查询" class="headerlink" title="慢查询"></a>慢查询</h2><h3 id="慢SQL优化全流程"><a href="#慢SQL优化全流程" class="headerlink" title="慢SQL优化全流程"></a>慢SQL优化全流程</h3><p><strong>阶段1：问题定位与数据采集</strong></p>
<ul>
<li>开启慢日志查询</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 动态开启（重启失效）</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> slow_query_log <span class="operator">=</span> <span class="string">&#x27;ON&#x27;</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> long_query_time <span class="operator">=</span> <span class="number">1</span>;  <span class="comment">-- 阈值设为1秒</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> slow_query_log_file <span class="operator">=</span> <span class="string">&#x27;/var/log/mysql/slow.log&#x27;</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 永久配置（my.cnf）</span><br><span class="line">[mysqld]</span><br><span class="line">slow_query_log = 1</span><br><span class="line">long_query_time = 1</span><br><span class="line">log_queries_not_using_indexes = 1  -- 记录未走索引的查询</span><br></pre></td></tr></table></figure>

<ul>
<li>实时监测工具</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查看当前运行中的慢查询</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.PROCESSLIST </span><br><span class="line"><span class="keyword">WHERE</span> <span class="type">TIME</span> <span class="operator">&gt;</span> <span class="number">2</span> <span class="keyword">AND</span> COMMAND <span class="operator">=</span> <span class="string">&#x27;Query&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 使用Percona Toolkit抓取问题SQL</span></span><br><span class="line">pt<span class="operator">-</span>query<span class="operator">-</span>digest <span class="operator">/</span>var<span class="operator">/</span>log<span class="operator">/</span>mysql<span class="operator">/</span>slow.log</span><br></pre></td></tr></table></figure>

<ul>
<li>关键性能指标</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">重点监控项：</span><br><span class="line">- QPS/TPS波动</span><br><span class="line">- CPU使用率（特别是%sys）</span><br><span class="line">- 锁等待时间(Innodb_row_lock_time_avg)</span><br><span class="line">- 缓冲池命中率(Innodb_buffer_pool_reads)</span><br></pre></td></tr></table></figure>



<p>Q：<code>IN</code> 和 <code>EXISTS</code> 的区别</p>
<p>当使用 <code>IN</code> 时，MySQL 会首先执行子查询，然后将子查询的结果集用于外部查询的条件。这意味着子查询的结果集需要全部加载到内存中。</p>
<p>而 <code>EXISTS</code> 会对外部查询的每一行，执行一次子查询。如果子查询返回任何行，则 <code>EXISTS</code> 条件为真。<code>EXISTS</code> 关注的是子查询是否返回行，而不是返回的具体值。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- IN 的临时表可能成为性能瓶颈</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> users </span><br><span class="line"><span class="keyword">WHERE</span> id <span class="keyword">IN</span> (<span class="keyword">SELECT</span> user_id <span class="keyword">FROM</span> orders <span class="keyword">WHERE</span> amount <span class="operator">&gt;</span> <span class="number">100</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- EXISTS 可以利用关联索引</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> users u</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">EXISTS</span> (<span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">FROM</span> orders o </span><br><span class="line">            <span class="keyword">WHERE</span> o.user_id <span class="operator">=</span> u.id <span class="keyword">AND</span> o.amount <span class="operator">&gt;</span> <span class="number">100</span>);</span><br></pre></td></tr></table></figure>

<p><code>IN</code> 适用于子查询结果集较小的情况。如果子查询返回大量数据，<code>IN</code> 的性能可能会下降，因为它需要将整个结果集加载到内存。</p>
<p>而 EXISTS 适用于子查询结果集可能很大的情况。由于 <code>EXISTS</code> 只需要判断子查询是否返回行，而不需要加载整个结果集，因此在某些情况下性能更好，特别是当子查询可以使用索引时。</p>
<p><strong>NULL值陷</strong></p>
<p><code>IN</code>: 如果子查询的结果集中包含 <code>NULL</code> 值，可能会导致意外的结果。例如，<code>WHERE column IN (subquery)</code>，如果 <code>subquery</code> 返回 <code>NULL</code>，则 <code>column IN (subquery)</code> 永远不会为真，除非 <code>column</code> 本身也为 <code>NULL</code>。</p>
<p><code>EXISTS</code>: 对 <code>NULL</code> 值的处理更加直接。<code>EXISTS</code> 只是检查子查询是否返回行，不关心行的具体值，因此不受 <code>NULL</code> 值的影响。</p>
<h3 id="为什么有时只查询一行但是很慢"><a href="#为什么有时只查询一行但是很慢" class="headerlink" title="为什么有时只查询一行但是很慢"></a>为什么有时只查询一行但是很慢</h3><ol>
<li>数据库表中数据量增加：随着表中数据量的增加，查询一行的时间可能会变得更长。</li>
<li>索引失效：如果查询条件中使用的列没有索引，或者索引失效（例如索引统计信息过期或者索引损坏），数据库可能会执行全表扫描或者其他低效的查询方法，从而导致查询一行的性能下降。</li>
<li>查询复杂度增加：如果查询的复杂度增加，例如涉及到多个表的联接、子查询、聚合函数等，查询一行的性能可能会受到影响。</li>
<li>数据库服务器负载增加：如果数据库服务器负载增加，例如同时有大量的查询和写入操作，数据库的性能可能会下降，从而导致查询一行变得很慢。</li>
</ol>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><h3 id="事务的基本特性和隔离级别"><a href="#事务的基本特性和隔离级别" class="headerlink" title="事务的基本特性和隔离级别"></a>事务的基本特性和隔离级别</h3><p>事务保证一组操作要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。</p>
<table>
<thead>
<tr>
<th>基本特性</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>原子性（<code>atomicity</code>）</td>
<td>事务中的操作要么全都执行，要么都不执行</td>
</tr>
<tr>
<td>一致性（<code>consistency</code>）</td>
<td>事务的执行要保证数据的完整性和一致性</td>
</tr>
<tr>
<td>隔离性（<code>isolation</code>）</td>
<td>事务的执行互不干扰</td>
</tr>
<tr>
<td>持久性（<code>durability</code>）</td>
<td>事务一旦提交，对数据的修改就永久保存到数据库中，不可撤销</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>事务可能引发的问题</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>脏读</td>
<td>A 事务读取 B 事务尚未提交的修改</td>
</tr>
<tr>
<td>不可重复读</td>
<td>A 事务多次读取同一数据，结果前后不一致</td>
</tr>
<tr>
<td>幻读</td>
<td>A 事务多次读取，数据总量前后不一致</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>说明</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody><tr>
<td><code>read uncommitted</code></td>
<td>一个事务执行过程中，能看到其他未提交事务做的变更</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>read committed</code></td>
<td>一个事务执行过程中，能看到其他已提交事务做的变更（MySQL 会在每个 SQL 语句开始执行时创建一个视图）</td>
<td></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>repeatable read</code></td>
<td>一个事务执行过程中，其他事务的变更对它不可见（MySQL 会在事务启动时创建一个视图，整个事务执行期间都使用这个视图）</td>
<td></td>
<td></td>
<td>✓</td>
</tr>
<tr>
<td><code>serializable</code></td>
<td>事务串行执行，隔离级别最高，不会出现上面所说的问题，但相应的效率也最低</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="MVCC实现原理"><a href="#MVCC实现原理" class="headerlink" title="MVCC实现原理"></a><code>MVCC</code>实现原理</h3><ul>
<li><code>Undo log</code>：每条数据维护多个历史版本</li>
<li><code>ReadView</code>：快照</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ReadView结构：</span><br><span class="line">&#123;</span><br><span class="line">  creator_trx_id: 150,      -- 当前事务ID</span><br><span class="line">  m_ids: [100, 120, 140],   -- 活跃事务ID列表</span><br><span class="line">  min_trx_id: 100,          -- 最小活跃事务ID</span><br><span class="line">  max_trx_id: 150           -- 预分配最大事务ID</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>可见性判断规则</strong>：</p>
<ol>
<li>数据版本<code>trx_id</code> &lt; <code>min_trx_id</code> → 可见</li>
<li><code>trx_id</code>在<code>m_ids</code>中 → 不可见</li>
<li><code>trx_id</code> &gt;&#x3D; <code>max_trx_id</code> → 不可见</li>
</ol>
<p>InnoDB默认会为每行数据生成两个隐藏列：</p>
<ul>
<li><code>DB_TRX_ID</code>：最后修改该行的事务ID</li>
<li><code>DB_ROLL_PTR</code>：指向<code>Undo Log</code>的回滚指针</li>
</ul>
<p>不同隔离级别下<code>ReadView</code>的生成时机：</p>
<ul>
<li><code>READ COMMITTED(RC)</code>：每次<code>SELECT</code>都会创建新的<code>ReadView</code></li>
<li><code>REPEATABLE READ(RR)</code>：事务中第一次<code>SELECT</code>时创建<code>ReadView</code></li>
</ul>
<h3 id="什么是间隙锁和临键锁"><a href="#什么是间隙锁和临键锁" class="headerlink" title="什么是间隙锁和临键锁"></a>什么是间隙锁和临键锁</h3><p><strong>间隙锁（<code>Gap Lock</code>）</strong></p>
<p>锁定记录之间的间隙，不锁定记录本身。防止幻读。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 表数据：5, 10, 15</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> users <span class="keyword">WHERE</span> id <span class="operator">&gt;</span> <span class="number">10</span> <span class="keyword">AND</span> id <span class="operator">&lt;</span> <span class="number">20</span> <span class="keyword">FOR</span> <span class="keyword">UPDATE</span>;</span><br></pre></td></tr></table></figure>

<p>这条语句会锁定区间 <code>(10,15)</code>、<code>(15,+∞)</code>，在事务执行期间，其他事务无法在这两个区间插入数据</p>
<p><strong>临键锁（<code>Next-Key Lock</code>）</strong></p>
<p>锁定记录本身及之前的间隙。同时防止幻读和不可重复读。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 事务A执行：</span><br><span class="line">SELECT * FROM users WHERE id &gt; 15 AND id &lt; 25 FOR UPDATE;</span><br><span class="line">-- 假设存在id=20的记录，临键锁会锁定：(15,20],(20,+∞)</span><br></pre></td></tr></table></figure>

<h3 id="什么是两阶段提交"><a href="#什么是两阶段提交" class="headerlink" title="什么是两阶段提交"></a>什么是两阶段提交</h3><p>两阶段提交的核心目的之一，就是为了协调 <strong>redo log (InnoDB 引擎层)</strong> 和 <strong>binlog (Server 层)</strong> 这两种位于不同层次、有各自内存 buffer 和刷盘策略的日志，在 <strong>刷盘时机</strong> 上保持一致，确保崩溃恢复后数据状态一致。</p>
<ol>
<li><strong>Prepare 阶段 (InnoDB):</strong> 将事务的 redo log 写入 redo log buffer <strong>并刷盘</strong>（根据 <code>innodb_flush_log_at_trx_commit</code>，通常此时已强制刷盘），标记状态为 <code>PREPARE</code>。<strong>此时 redo log 在磁盘上持久化了“这个事务准备修改什么”。</strong></li>
<li><strong>Write &amp; Sync Binlog 阶段 (Server):</strong> 将事务的 binlog 事件写入 binlog cache <strong>并刷盘</strong>（根据 <code>sync_binlog</code>，通常此时也强制刷盘）。<strong>此时 binlog 在磁盘上持久化了“这个事务执行了什么操作”。</strong></li>
<li><strong>Commit 阶段 (InnoDB):</strong> 在 redo log 中写入一个 <code>COMMIT</code> 标记（通常只需写 redo log buffer，不一定立刻刷盘，因为前两步已保证关键信息持久化）。<strong>标记事务在引擎层正式提交。</strong></li>
</ol>
<h2 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h2><h3 id="什么是分库分表"><a href="#什么是分库分表" class="headerlink" title="什么是分库分表"></a>什么是分库分表</h3><ol>
<li><strong>分库 (Database Sharding):</strong><ul>
<li><strong>概念：</strong> 将一个数据库中的数据，按照某种规则（如用户ID、订单日期、地理位置等）分散到多个<strong>物理上独立</strong>的数据库实例中。</li>
<li><strong>目的：</strong><ul>
<li><strong>分担写负载&#x2F;读负载：</strong> 多个数据库实例可以同时处理写入和读取请求，显著提升整体吞吐量。</li>
<li><strong>突破单机连接数限制：</strong> 每个数据库实例有自己的连接池。</li>
<li><strong>提高可用性：</strong> 一个数据库实例故障，不影响其他实例上的服务（需要配合高可用方案）。</li>
<li><strong>资源隔离：</strong> 不同业务模块或不同类型的数据可以部署到不同的数据库集群，互不影响。</li>
</ul>
</li>
</ul>
</li>
<li><strong>分表 (Table Sharding&#x2F;Partitioning):</strong><ul>
<li><strong>概念：</strong> 将一张表中的数据，按照某种规则（通常是基于某个字段的值，如用户ID、时间戳、哈希值等）分散到<strong>同一个数据库实例内</strong>的多张结构相同的表中，或者分散到<strong>不同数据库实例</strong>的多张表中（此时是分库分表的结合）。</li>
<li><strong>目的：</strong><ul>
<li><strong>解决单表数据量过大问题：</strong> 这是最核心的驱动力。单表数据量过大（如数千万、上亿行）会导致索引树变得非常深，查询效率急剧下降，DDL操作（如加索引、修改表结构）耗时极长且可能锁表，数据备份恢复困难。</li>
<li><strong>提升查询效率：</strong> 针对特定分片键的查询，可以快速定位到具体的分片表，避免扫描全量数据。</li>
<li><strong>减少锁竞争：</strong> 写操作分散到多张表，减少了锁争用的概率。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="常见拆分维度"><a href="#常见拆分维度" class="headerlink" title="常见拆分维度"></a>常见拆分维度</h3><ul>
<li><strong>水平拆分 (Horizontal Sharding&#x2F;Partitioning):</strong><ul>
<li>按行拆分。将表中的不同行记录分散到不同的库&#x2F;表。</li>
<li>拆分规则：基于某个字段的值（分片键），如：<ul>
<li><strong>范围分片：</strong> 按时间范围（如按月、按年）、按ID范围（如 1-100万在表1，100万-200万在表2）。</li>
<li><strong>哈希分片：</strong> 对分片键进行哈希运算，根据哈希值取模或其他算法分配到不同库表。能较均匀分布数据，但范围查询困难。</li>
<li><strong>地理位置分片：</strong> 按用户或业务所属地区。</li>
<li><strong>业务分片：</strong> 按业务线、租户ID等。</li>
</ul>
</li>
</ul>
</li>
<li><strong>垂直拆分 (Vertical Sharding&#x2F;Partitioning):</strong><ul>
<li>按列拆分。将一张宽表的不同列拆分到不同的库&#x2F;表中。</li>
<li>通常用于：<ul>
<li>将访问频率高的列和访问频率低的列（如大文本、BLOB）分开。</li>
<li>将核心业务字段和扩展字段分开。</li>
<li>将不同业务模块的字段拆分到独立的库或表中（这通常也属于分库的范畴）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="分库分表带来的挑战"><a href="#分库分表带来的挑战" class="headerlink" title="分库分表带来的挑战"></a>分库分表带来的挑战</h3><ul>
<li><strong>分布式事务：</strong> 跨库&#x2F;跨表的操作难以保证强一致性，需要使用分布式事务解决方案（如2PC, 3PC, TCC, Saga, 本地消息表等），增加了复杂性和性能开销。</li>
<li><strong>跨库&#x2F;跨表JOIN：</strong> 原本简单的JOIN查询变得非常困难且低效，通常需要业务层处理（多次查询+内存JOIN）或使用异构索引（如Elasticsearch）。</li>
<li><strong>全局唯一主键：</strong> 单机自增ID不再适用，需要分布式ID生成方案（Snowflake, UUID, Redis, 数据库号段等）。</li>
<li><strong>分片键选择：</strong> 分片键的选择至关重要，直接影响数据分布均匀性、查询效率、扩容难易度。一旦选定，后期修改成本极高。</li>
<li><strong>扩容复杂性：</strong> 水平扩容（增加分片节点）通常涉及数据迁移，需要精心设计，可能影响服务。</li>
<li><strong>运维复杂度：</strong> 需要管理更多的数据库实例和表，监控、备份、升级、故障排查等运维工作量和复杂度成倍增加。</li>
<li><strong>SQL限制：</strong> 部分SQL语句（如未带分片键的条件查询、复杂子查询、排序分页）可能无法高效执行或需要改写。</li>
</ul>
<h3 id="多大的数据量需要考虑分库分表"><a href="#多大的数据量需要考虑分库分表" class="headerlink" title="多大的数据量需要考虑分库分表"></a>多大的数据量需要考虑分库分表</h3><p><strong>这是一个非常常见但也非常难给出绝对数字的问题。没有放之四海而皆准的阈值，需要综合考量多个因素：</strong></p>
<ol>
<li><strong>数据量 (最核心因素)：</strong><ul>
<li><strong>单表行数：</strong> 这是最直观的指标。业界经验值通常认为：<ul>
<li><code>百万级别 (1M+)</code>：需要开始关注单表性能，优化索引和SQL。</li>
<li><code>千万级别 (10M+)</code>：性能瓶颈开始显现（如复杂查询变慢、count(<em>)慢、DDL操作耗时）。*<em>这是需要认真评估是否需要分表的重要信号区。</em></em></li>
<li><code>亿级别 (100M+)</code>：<strong>绝大多数情况下，单表已难以支撑高效操作，强烈建议进行分表。</strong> 索引维护成本、查询效率、维护操作（备份、迁移、加字段）都成为严重问题。</li>
</ul>
</li>
<li><strong>表数据大小：</strong> 即使行数不多，但如果单行数据非常大（如包含大文本、BLOB字段），导致单表数据文件巨大（如几十GB甚至上百GB），也会严重影响性能（特别是全表扫描、备份恢复）和磁盘IO，需要考虑垂直拆分或分表。</li>
</ul>
</li>
<li><strong>并发访问量 (QPS&#x2F;TPS)：</strong><ul>
<li>即使数据量不大，但<strong>极高的并发读写请求</strong>也可能压垮单库单表（连接数耗尽、CPU&#x2F;IO瓶颈、锁竞争激烈）。</li>
<li>如果单库实例的连接数、CPU利用率、磁盘IO持续在高位（如&gt;70%），且优化SQL和索引效果有限，就需要考虑分库来分担负载。</li>
</ul>
</li>
<li><strong>硬件配置：</strong><ul>
<li>使用顶配的SSD、大内存、多核CPU的数据库服务器，能支撑的单表数据量和并发量远高于普通配置的机器。评估是否需要分库分表时，要基于当前和未来规划的实际硬件水平。</li>
</ul>
</li>
<li><strong>业务复杂度和查询模式：</strong><ul>
<li>业务逻辑简单，查询模式固定（总是通过高效索引访问），单表能支撑的数据量会更大。</li>
<li>业务复杂，涉及多表关联、复杂查询、聚合、排序分页等操作，即使数据量不大，也可能因为查询效率低下而需要提前考虑拆分。</li>
</ul>
</li>
<li><strong>增长速度：</strong><ul>
<li>数据量增长<strong>非常快</strong>的业务（如日增百万级记录），即使当前数据量不大，也需要提前规划分库分表方案，避免未来被动。</li>
</ul>
</li>
<li><strong>可用性和扩展性要求：</strong><ul>
<li>对系统可用性要求极高（如金融核心系统），需要避免单点故障，分库本身（配合主从复制）能提高可用性。</li>
<li>明确知道业务未来会快速增长，需要系统具备水平扩展能力，分库分表是核心手段。</li>
</ul>
</li>
</ol>
<p><strong>总结判断标准</strong>（经验法则，非绝对）</p>
<ol>
<li><strong>预警信号 (开始认真评估)：</strong><ul>
<li>单表行数逼近或超过 <code>500万 - 1000万</code>。</li>
<li>单表数据文件大小达到 <code>几十GB</code>。</li>
<li>关键业务查询响应时间明显变长（&gt;几百毫秒），且优化空间有限。</li>
<li>DDL操作（如加索引、改字段）耗时过长（&gt;分钟级），影响业务。</li>
<li>数据库服务器CPU、IO、连接数等关键指标持续高位（&gt;70%）。</li>
<li>数据量或并发量预计在未来6-12个月内会增长数倍。</li>
</ul>
</li>
<li><strong>强烈建议实施：</strong><ul>
<li>单表行数超过 <code>5000万 - 1亿</code>。</li>
<li>单表数据文件大小达到 <code>数百GB</code>。</li>
<li>数据库性能瓶颈成为业务发展的明显阻碍。</li>
<li>高并发场景下，频繁出现锁超时、连接池耗尽等问题。</li>
</ul>
</li>
</ol>
<p><strong>重要建议</strong></p>
<ol>
<li><strong>不要过早优化：</strong> 分库分表带来巨大复杂性。在数据量和并发量真正成为瓶颈之前，优先使用更简单的手段：<ul>
<li><strong>硬件升级：</strong> 提升CPU、内存、换SSD。</li>
<li><strong>数据库优化：</strong> 优化慢查询SQL、合理设计索引、调整数据库参数。</li>
<li><strong>读写分离：</strong> 用主库写，多个从库读，分担读负载。</li>
<li><strong>缓存：</strong> 使用Redis、Memcached等缓存热点数据，减少数据库访问。</li>
<li><strong>归档&#x2F;清理：</strong> 将历史冷数据迁移到归档库或删除。</li>
<li><strong>数据库分区 (Partitioning)：</strong> 如果数据库本身支持（如MySQL的Partitioning），可以在单库内进行水平分区，管理比单表大得多的数据量，比应用层分表简单很多。但分区不能解决单库资源瓶颈（CPU&#x2F;IO&#x2F;连接数）和写负载问题。</li>
</ul>
</li>
<li><strong>精心设计：</strong> 一旦决定分库分表，必须投入精力做好设计，尤其是<strong>分片键的选择</strong>、<strong>拆分规则</strong>、<strong>分布式ID</strong>、<strong>分布式事务方案</strong>、<strong>数据迁移和扩容方案</strong>。前期设计失误会导致后期维护成本剧增。</li>
<li><strong>选择合适的中间件：</strong> 使用成熟的数据库中间件（如ShardingSphere, MyCat, Vitess等）可以大大简化分库分表的开发和管理工作，它们帮你处理路由、分布式事务、跨库查询等难题。</li>
</ol>
<p><strong>结论：</strong> 分库分表是解决海量数据和高并发问题的终极手段之一，但其复杂性极高。触发点通常是单表数据量达到<strong>千万级（10M+）并伴随性能瓶颈</strong>，或<strong>高并发导致单库资源耗尽</strong>。务必优先尝试更简单的优化方案，并在真正需要时，进行充分评估和精心设计。没有固定的“多大必须分”的数字，必须结合具体业务场景、数据特性、硬件配置和增长预期综合判断。</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="char-100-和-varchar-100-的区别"><a href="#char-100-和-varchar-100-的区别" class="headerlink" title="char(100) 和 varchar(100) 的区别"></a>char(100) 和 varchar(100) 的区别</h3><p><strong>核心区别总结</strong></p>
<table>
<thead>
<tr>
<th align="left"><strong>特性</strong></th>
<th align="left"><code>CHAR(100)</code></th>
<th align="left"><code>VARCHAR(100)</code></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>类型名称</strong></td>
<td align="left">定长字符串</td>
<td align="left">变长字符串</td>
</tr>
<tr>
<td align="left"><strong>存储方式</strong></td>
<td align="left">始终占用 100 字符空间（不足补空格）</td>
<td align="left">按实际字符数存储 + 额外长度开销</td>
</tr>
<tr>
<td align="left"><strong>存储 “abc” 的占用</strong></td>
<td align="left">100 字节（固定）</td>
<td align="left">3 字节 + 1~2 字节长度开销 ≈ 4 字节</td>
</tr>
<tr>
<td align="left"><strong>空格处理</strong></td>
<td align="left">插入时会自动补空格，查询时自动去除</td>
<td align="left">保留原始空格，不自动补齐</td>
</tr>
<tr>
<td align="left"><strong>查询速度</strong></td>
<td align="left">更快（定长，直接定位）</td>
<td align="left">稍慢（需计算位置）</td>
</tr>
<tr>
<td align="left"><strong>适用场景</strong></td>
<td align="left">长度固定的数据（如国家代码、MD5）</td>
<td align="left">长度不固定的数据（如用户名、地址）</td>
</tr>
</tbody></table>
<h3 id="为什么不建议使用-text-作为字段类型"><a href="#为什么不建议使用-text-作为字段类型" class="headerlink" title="为什么不建议使用 text 作为字段类型"></a>为什么不建议使用 text 作为字段类型</h3><ol>
<li><p><strong>性能影响</strong>：</p>
<p>- <strong>查询性能</strong>：<code>TEXT</code>字段通常比定长或较短的变长字符串（如<code>VARCHAR</code>）占用更多空间。当查询需要读取或排序这些字段时，由于数据量大，I&#x2F;O操作和内存消耗会增加，从而降低查询速度。</p>
<p>- <strong>临时表和排序</strong>：如果查询涉及对<code>TEXT</code>字段进行排序或分组，MySQL等数据库可能会使用磁盘临时表而非内存临时表，因为内存临时表有大小限制，这会导致性能下降。</p>
</li>
<li><p><strong>内存使用</strong>：</p>
<p>- 数据库在读取行时，通常会将整行数据加载到内存中（尤其是使用InnoDB引擎时，会读取整个页）。如果表中包含多个<code>TEXT</code>字段，即使查询不需要这些字段，也可能导致内存浪费，因为行数据可能被部分读取（但InnoDB的页大小固定，一页可能包含多行，所以大字段会减少一页中存放的行数，增加I&#x2F;O次数）。</p>
</li>
<li><p><strong>索引限制</strong>：</p>
<p>- 在MySQL中，对于<code>TEXT</code>类型（以及<code>BLOB</code>类型）的字段，如果要在其上创建索引，必须指定前缀长度（即只对字段的前N个字符建立索引）。这可能导致索引无法完全覆盖字段内容，影响索引效率。</p>
<p>- 此外，<code>TEXT</code>字段不能作为主键（或唯一索引的完整字段）使用，因为可能会超过索引的最大长度限制。</p>
</li>
<li><p><strong>存储空间</strong>：</p>
<p>- <code>TEXT</code>类型的数据存储在行外（off-page），即实际数据存储在单独的区域，而行数据中只存储指向实际数据的指针。这会导致额外的I&#x2F;O操作（因为需要访问两个地方才能获取完整数据），尤其是在使用<code>SELECT *</code>查询时。</p>
</li>
<li><p><strong>默认值问题</strong>：</p>
<p>- 在MySQL中，<code>TEXT</code>字段不能有默认值（除了MySQL 8.0.13之后支持对<code>TEXT</code>类型设置默认值为表达式，但直接的字面量默认值仍不被允许）。这可能导致应用层需要处理空值的情况。</p>
</li>
<li><p><strong>不必要的灵活性</strong>：</p>
<p>- 使用<code>TEXT</code>类型可能会允许存储非常大的数据，但实际业务可能并不需要这么大的存储。如果字段实际存储的内容都很短（例如，一个简介字段通常只有几百个字符），那么使用<code>VARCHAR</code>更为合适，因为<code>VARCHAR</code>在存储短字符串时效率更高。</p>
</li>
</ol>
<p><strong>建议的替代方案</strong>：</p>
<p>- 如果字符串长度有限且可预估（例如，小于65535字节），优先使用<code>VARCHAR(n)</code>，其中<code>n</code>为最大预期长度。</p>
<p>- 对于非常大的文本数据（如文章内容），确实需要使用<code>TEXT</code>类型时，考虑将其单独存放在一张表中，与原表通过外键关联，避免大字段影响主表的查询效率。</p>
<p>- 在查询时避免使用<code>SELECT *</code>，只选择需要的字段，特别是避免不必要的<code>TEXT</code>字段。</p>
<h3 id="查询语句的执行顺序"><a href="#查询语句的执行顺序" class="headerlink" title="查询语句的执行顺序"></a>查询语句的执行顺序</h3><p>MySQL 分为 server 层和存储引擎层。</p>
<p>server 层涵盖 MySQL 大多数核心功能（如存储过程、触发器、视图等）和所有内置函数（如日期、时间、数学函数等）。</p>
<p>存储引擎层负责数据的存储和提取。</p>
<p><code>from</code> -&gt; <code>where</code> -&gt; <code>group by</code> -&gt; <code>having</code> -&gt; <code>select</code> -&gt; <code>distinct</code> -&gt; <code>order by</code> -&gt; <code>limit</code></p>
<img src="/post/32511a71/1726212535664-4bb3f3ff-704a-4706-84c8-a046a8486657.webp" class="" title="img">

<h3 id="一条查询语句的执行流程"><a href="#一条查询语句的执行流程" class="headerlink" title="一条查询语句的执行流程"></a>一条查询语句的执行流程</h3><h3 id="一条更新语句的执行过程"><a href="#一条更新语句的执行过程" class="headerlink" title="一条更新语句的执行过程"></a>一条更新语句的执行过程</h3><p>一条 <code>UPDATE</code> 语句在 MySQL（尤其是 InnoDB 存储引擎）中的执行过程是一个涉及多个组件（解析器、优化器、执行引擎、存储引擎、缓冲池、日志系统、锁机制等）协同工作的复杂过程。下面是其核心步骤的详细分解：</p>
<ol>
<li><strong>连接与请求接收</strong></li>
</ol>
<ul>
<li>客户端应用程序（如 Java 程序、MySQL CLI）通过连接器建立与 MySQL 服务器的连接。</li>
<li>服务器验证用户身份和权限。</li>
<li>客户端发送 <code>UPDATE</code> SQL 语句到服务器。</li>
</ul>
<ol start="2">
<li><strong>解析与优化（Server 层）</strong></li>
</ol>
<ul>
<li><strong>解析器：</strong><ul>
<li>进行词法分析：识别 <code>UPDATE</code>、表名、<code>SET</code>、列名、<code>=</code>、值、<code>WHERE</code> 等关键字和标识符。</li>
<li>进行语法分析：检查语句是否符合 SQL 语法规则，构建抽象语法树。</li>
</ul>
</li>
<li><strong>预处理器：</strong><ul>
<li>检查表和列是否存在。</li>
<li>解析名称和别名。</li>
<li>检查用户是否有执行 <code>UPDATE</code> 的权限。</li>
</ul>
</li>
<li><strong>优化器：</strong><ul>
<li><strong>关键步骤！</strong> 基于统计信息（表大小、索引分布、基数等）选择它认为最高效的执行计划。</li>
<li>决定：<ul>
<li>使用哪个索引（主键索引、二级索引）来定位需要更新的行。这是影响速度的关键因素。</li>
<li>是否可以使用索引条件下推。</li>
<li>是否需要进行全表扫描（如果 <code>WHERE</code> 条件无法有效利用索引）。</li>
</ul>
</li>
<li>生成具体的执行计划。</li>
</ul>
</li>
</ul>
<ol start="3">
<li><strong>执行引擎调用存储引擎（Server 层 -&gt; 存储引擎层）</strong></li>
</ol>
<ul>
<li>执行引擎根据优化器选择的执行计划，调用存储引擎（InnoDB）提供的接口来执行实际的数据查找和修改操作。</li>
</ul>
<ol start="4">
<li><strong>InnoDB 存储引擎内部处理</strong></li>
</ol>
<ul>
<li><strong>缓冲池查找：</strong><ul>
<li>执行引擎告知 InnoDB 要更新哪些行（通过 <code>WHERE</code> 条件定位）。</li>
<li>InnoDB 首先在 <strong>Buffer Pool（缓冲池）</strong> 中查找这些行所在的数据页。</li>
<li>如果数据页不在 Buffer Pool 中，则从磁盘上的 <code>.ibd</code> 数据文件中将其加载到 Buffer Pool。</li>
</ul>
</li>
<li><strong>写 Undo Log：</strong><ul>
<li><strong>关键步骤！</strong> 在修改 Buffer Pool 中的数据页<strong>之前</strong>，InnoDB 会先将这行数据的旧版本（修改前的状态）写入 <strong>Undo Log（回滚日志）</strong>。</li>
<li><strong>目的：</strong><ul>
<li>支持事务回滚：如果事务需要回滚，可以用 Undo Log 中的旧数据覆盖修改。</li>
<li>实现 MVCC：其他并发事务如果需要读取这行数据的旧版本（基于它们的 Read View），可以通过 Undo Log 链找到。</li>
</ul>
</li>
<li>Undo Log 存储在 Undo Tablespaces 中。</li>
</ul>
</li>
<li><strong>修改 Buffer Pool：</strong><ul>
<li>将 Buffer Pool 中对应的数据页中的行数据更新为新值。</li>
<li>此时数据页变成<strong>脏页</strong>（内存中的数据与磁盘数据不一致）。</li>
</ul>
</li>
<li><strong>写 Redo Log Buffer：</strong><ul>
<li><strong>关键步骤！</strong> 在脏页刷盘<strong>之前</strong>，InnoDB 会先把对数据页所做的物理修改（字节级别的变化）记录到内存中的 <strong>Redo Log Buffer（重做日志缓冲区）</strong>。</li>
<li><strong>目的：</strong> 保证事务的持久性。即使系统崩溃，重启后也能根据 Redo Log 重做未持久化的修改。</li>
</ul>
</li>
<li><strong>处理二级索引（如果涉及）：</strong><ul>
<li>如果更新的列包含在二级索引中，或者更新影响了索引列的值（如 <code>UPDATE users SET username=&#39;new&#39; WHERE id=1</code>，且 <code>username</code> 上有索引），则需要更新对应的二级索引页。</li>
<li>更新二级索引页同样遵循“写 Undo Log -&gt; 修改 BP -&gt; 写 Redo Log Buffer”的过程。</li>
<li>如果启用 <strong>Change Buffer</strong>，对于非唯一的二级索引的更新操作（INSERT&#x2F;DELETE&#x2F;UPDATE），可能不会立即加载索引页到 BP，而是先将变更记录到 Change Buffer 中，等到后续需要读取该索引页时再合并操作，从而减少随机 I&#x2F;O。</li>
</ul>
</li>
</ul>
<ol start="5">
<li><strong>事务提交（关键步骤！）</strong></li>
</ol>
<ul>
<li>当用户显式执行 <code>COMMIT</code> 或自动提交开启时，事务进入提交阶段。</li>
<li><strong>Write Redo Log：</strong><ul>
<li><strong>两阶段提交的核心第一步：</strong> 将 Redo Log Buffer 中与该事务相关的所有日志记录<strong>顺序、快速</strong>地写入（<code>write()</code> 系统调用）磁盘上的 <strong>Redo Log File（通常是 <code>ib_logfile0</code>, <code>ib_logfile1</code>）</strong>。此时数据可能还在内存（Buffer Pool）。</li>
<li><strong><code>fsync()</code>：</strong> 为了确保日志真正落盘（防止操作系统缓存丢失），通常需要调用 <code>fsync()</code>（或配置决定的类似机制）强制将文件系统缓存中的日志数据刷到物理磁盘。<strong>这是保证持久性（D）的关键点，也是相对耗时的操作。</strong></li>
</ul>
</li>
<li><strong>写 Binlog（如果启用）：</strong><ul>
<li>在写入 Redo Log <strong>之后</strong>（在组提交优化下顺序可能不同，但逻辑上 Redo Prepare 在 Binlog 之前），Server 层会将更新操作的逻辑语句或行变更写入 <strong>Binlog（二进制日志）</strong>。Binlog 用于主从复制和数据恢复。</li>
<li>同样需要 <code>fsync()</code> 确保 Binlog 落盘（取决于 <code>sync_binlog</code> 配置）。</li>
</ul>
</li>
<li><strong>Redo Log Commit：</strong><ul>
<li><strong>两阶段提交的核心第二步：</strong> 在 Binlog 成功写入并 <code>fsync()</code> 后，InnoDB 在 Redo Log 中写入一个特殊的 <strong>Commit Record</strong>，标记该事务<strong>已提交</strong>。</li>
<li>再次 <code>fsync()</code> Redo Log（如果配置需要）。</li>
</ul>
</li>
<li><strong>释放锁：</strong> 事务提交后，InnoDB 释放该事务持有的所有锁（行锁、间隙锁等）。</li>
<li><strong>返回成功：</strong> 向客户端返回执行成功的消息。</li>
</ul>
<ol start="6">
<li><strong>后台刷脏页</strong></li>
</ol>
<ul>
<li><strong>非同步操作！</strong> 提交成功<strong>并不保证</strong>脏页立即写入磁盘数据文件（<code>.ibd</code>）。写入 Redo Log 已经保证了持久性。</li>
<li>InnoDB 有后台线程（Page Cleaner Thread）负责在以下时机将脏页异步刷新回磁盘：<ul>
<li>当 Buffer Pool 中脏页比例过高时（由 <code>innodb_max_dirty_pages_pct</code> 等参数控制）。</li>
<li>当系统空闲时。</li>
<li>当 Redo Log 空间即将用完时（需要回收旧的 Redo Log 空间，这要求对应的脏页必须先刷盘）。</li>
<li>关闭数据库时。</li>
</ul>
</li>
<li>刷脏页时，会利用 Doublewrite Buffer 机制来避免部分写失败导致的数据页损坏。</li>
</ul>
<p><strong>关键点与注意事项</strong></p>
<ol>
<li><strong>Buffer Pool 核心作用：</strong> 所有数据读写都发生在内存（Buffer Pool），极大提升性能。</li>
<li><strong>WAL 机制：</strong> Write-Ahead Logging (Redo Log) 是保证持久性和崩溃恢复的核心。先写日志（顺序写，快），后刷脏页（随机写，慢）。</li>
<li><strong>两阶段提交：</strong> 协调 Redo Log 和 Binlog 的写入，保证这两个关键日志在崩溃时状态一致，是数据一致性和主从复制的基石。</li>
<li><strong>Undo Log 与 MVCC：</strong> Undo Log 支持回滚和实现非锁定读（MVCC），是多版本并发控制的关键。</li>
<li><strong>Change Buffer：</strong> 优化非唯一二级索引更新的利器，减少随机 I&#x2F;O。</li>
<li><strong>锁机制：</strong> InnoDB 在查找和更新行时会加锁（行锁、间隙锁等），以保证事务的隔离性。锁在事务提交或回滚时释放。</li>
<li><strong>异步刷盘：</strong> 数据文件（.ibd）的写入是异步的，依赖于 Redo Log 保证持久性。</li>
<li><strong>性能瓶颈：</strong> <code>UPDATE</code> 性能受索引使用、锁竞争、Redo Log&#x2F;Binlog 刷盘策略、磁盘 I&#x2F;O 能力等因素影响。</li>
</ol>
<h3 id="EXPLAIN-字段说明"><a href="#EXPLAIN-字段说明" class="headerlink" title="EXPLAIN 字段说明"></a><code>EXPLAIN</code> 字段说明</h3><p>通常<code>EXPALIN</code>查询语句的输出如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span> <span class="comment">// 每个select语句对应一个唯一的id</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询类型：</span></span><br><span class="line"><span class="comment">     * SIMPLE：不包含UNION或子查询的select（连接查询的每个查询都是simple查询）</span></span><br><span class="line"><span class="comment">     * PRIMARY：最外层查询</span></span><br><span class="line"><span class="comment">     * UNION</span></span><br><span class="line"><span class="comment">     * ...</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="attr">&quot;select_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;SIMPLE&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="string">&quot;users&quot;</span><span class="punctuation">,</span> <span class="comment">// 要查询的表</span></span><br><span class="line">    <span class="attr">&quot;partitions&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="comment">// 分区信息</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 针对单表的访问方法：</span></span><br><span class="line"><span class="comment">     * system：当表中只有一条记录，并且该表使用的存储引擎的统计数据是精确的，访问方法就是system</span></span><br><span class="line"><span class="comment">     * constant：根据主键或唯一索引列与常数进行等值匹配时，访问方法就是const</span></span><br><span class="line"><span class="comment">     * eq_ref：连接查询中对被驱动表的主键或不允许为NULL的唯一索引进行等值查询时，访问方法就是eq_ref</span></span><br><span class="line"><span class="comment">     * ref：通过普通二级索引列与常量进行等值匹配时，对该表的访问方法就是 ref</span></span><br><span class="line"><span class="comment">     * ref_or_null：select * from single_table where key1 = &#x27;abc&#x27; or key1 is NULL;</span></span><br><span class="line"><span class="comment">     * index_merge：使用多个索引进行等值匹配</span></span><br><span class="line"><span class="comment">     * unique_subquery：在子查询中使用主键或不允许存储NULL值的唯一二级索引进行等值匹配</span></span><br><span class="line"><span class="comment">     * index_subquery：在子查询中使用普通二级索引进行等值匹</span></span><br><span class="line"><span class="comment">     * range：利用索引进行范围查询</span></span><br><span class="line"><span class="comment">     * index：当可以使用索引覆盖，但需要扫描全部索引记录</span></span><br><span class="line"><span class="comment">     * all：全表扫描</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ref&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;possible_keys&quot;</span><span class="punctuation">:</span> <span class="string">&quot;idx_composite&quot;</span><span class="punctuation">,</span> <span class="comment">// 可能使用的索引</span></span><br><span class="line">    <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;idx_composite&quot;</span><span class="punctuation">,</span> <span class="comment">// 实际使用的索引</span></span><br><span class="line">    <span class="attr">&quot;key_len&quot;</span><span class="punctuation">:</span> <span class="string">&quot;208&quot;</span><span class="punctuation">,</span> <span class="comment">// 实际使用的索引长度</span></span><br><span class="line">    <span class="attr">&quot;ref&quot;</span><span class="punctuation">:</span> <span class="string">&quot;const&quot;</span><span class="punctuation">,</span> <span class="comment">// 使用索引列等值查询时，与索引列进行等值匹配的对象信息</span></span><br><span class="line">    <span class="attr">&quot;rows&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span> <span class="comment">// 预估需要读取的记录行数</span></span><br><span class="line">    <span class="attr">&quot;filtered&quot;</span><span class="punctuation">:</span> <span class="number">100.0</span><span class="punctuation">,</span> <span class="comment">// 过滤后剩余记录行数百分比</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 额外信息：</span></span><br><span class="line"><span class="comment">     * Using index：使用覆盖索引</span></span><br><span class="line"><span class="comment">     * Using index condition：使用索引条件下推</span></span><br><span class="line"><span class="comment">     * Using where：需要在server层判断条件是否成立</span></span><br><span class="line"><span class="comment">     * Using join buffer：执行连接查询时，被驱动表不能有效利用索引加快访问速度时，会分配一块内存用来保存被驱动表的查询结果，</span></span><br><span class="line"><span class="comment">     					  利用join buffer可以减少访问被驱动表的次数</span></span><br><span class="line"><span class="comment">     * Using filesort：</span></span><br><span class="line"><span class="comment">     * Using temporary</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="attr">&quot;Extra&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Using index&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<h3 id="为什么InnoDB不保存表的总行数"><a href="#为什么InnoDB不保存表的总行数" class="headerlink" title="为什么InnoDB不保存表的总行数"></a>为什么InnoDB不保存表的总行数</h3><p>与MyISAM保存表的总行数不同，InnoDB统计行数需要扫描全表，因为MVCC，同一时刻多个查询返回的行数可能不一致。</p>
<p>对于需要经常统计表的行数的解决办法：</p>
<ul>
<li>在缓存（如 Redis）中保存计数</li>
<li>在 MySQL 中保存计数</li>
</ul>
<h3 id="count-、count-1-、count-id-、count-字段-有什么区别"><a href="#count-、count-1-、count-id-、count-字段-有什么区别" class="headerlink" title="count(*)、count(1)、count(id)、count(字段)有什么区别"></a><code>count(*)、count(1)、count(id)、count(字段)</code>有什么区别</h3><table>
<thead>
<tr>
<th><strong>语法</strong></th>
<th><strong>统计逻辑</strong></th>
<th><strong>是否包含 NULL</strong></th>
</tr>
</thead>
<tbody><tr>
<td><code>COUNT(*)</code></td>
<td>统计所有行（包括所有列），即使所有字段都为 <code>NULL</code> 也会计数</td>
<td><strong>包含</strong></td>
</tr>
<tr>
<td><code>COUNT(1)</code></td>
<td>统计所有行（<code>1</code> 是常量表达式，与列无关）</td>
<td><strong>包含</strong></td>
</tr>
<tr>
<td><code>COUNT(id)</code></td>
<td>统计 <code>id</code> 列中 <strong>非 NULL</strong> 的行数（<code>id</code> 是主键或普通列）</td>
<td><strong>不包含 NULL</strong></td>
</tr>
<tr>
<td><code>COUNT(某个字段)</code></td>
<td>统计该字段中 <strong>非 NULL</strong> 的行数（如果字段允许 <code>NULL</code>）</td>
<td><strong>不包含 NULL</strong></td>
</tr>
</tbody></table>
<p>性能：<code>count(字段)</code> &lt; <code>count(主键)</code> &lt; <code>count(1)</code> ≈ <code>count(*)</code></p>
<p><code>count(主键/字段)</code> 的效率更低的原因是需要解析数据行，并拷贝要返回的字段值。</p>
<h3 id="InnoDB和MyISAM的区别"><a href="#InnoDB和MyISAM的区别" class="headerlink" title="InnoDB和MyISAM的区别"></a>InnoDB和MyISAM的区别</h3><table>
<thead>
<tr>
<th></th>
<th>MyISAM</th>
<th>InnoDB</th>
</tr>
</thead>
<tbody><tr>
<td>锁</td>
<td>表级锁</td>
<td>行级锁</td>
</tr>
<tr>
<td>事务支持</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>索引结构</td>
<td>B树</td>
<td>B+树</td>
</tr>
<tr>
<td>全文检索</td>
<td>支持</td>
<td>5.5版本后支持</td>
</tr>
</tbody></table>
<p>总体来说，如果需要支持事务、外键约束和高并发访问，那么InnoDB是更好的选择。如果需要进行全文检索，那么MyISAM是更好的选择。但是需要注意的是，MySQL 5.5版本之后，InnoDB已经支持了全文检索。</p>
<h3 id="为什么不建议使用text类型"><a href="#为什么不建议使用text类型" class="headerlink" title="为什么不建议使用text类型"></a>为什么不建议使用<code>text</code>类型</h3><p>在数据库设计中，文本类型字段（如MySQL中的TEXT，PostgreSQL中的TEXT等）通常用于存储大量文本数据。虽然它们可以存储大量数据，但在某些情况下不建议使用，原因如下：</p>
<ol>
<li><strong>性能问题</strong>：TEXT类型通常存储在数据库的主表之外（比如在MySQL的InnoDB中，TEXT和BLOB类型在记录较大时可能存储在溢出页），这可能导致额外的磁盘I&#x2F;O。当查询中包含TEXT字段时，可能需要访问多个页，从而降低查询速度。</li>
<li><strong>内存使用</strong>：在处理查询时，数据库可能会为TEXT字段分配大量内存，尤其是当使用临时表或排序时。这可能导致内存使用过高，影响数据库性能。</li>
<li><strong>索引限制</strong>：对于TEXT类型，通常不能直接创建索引（除非指定前缀索引），而且前缀索引可能不够精确。在MySQL中，对TEXT列建立索引必须指定前缀长度，这可能导致索引效率不高。</li>
<li><strong>默认值问题</strong>：在某些数据库系统中（如MySQL 5.6之前的版本），TEXT字段不能有默认值。虽然较新的版本已经支持，但仍有其他限制。</li>
<li><strong>存储空间</strong>：TEXT类型通常占用更多存储空间，因为数据库可能会为这些字段分配额外的空间以应对可能的增长。</li>
<li><strong>复制和恢复</strong>：由于TEXT字段可能包含大量数据，在数据库复制（如主从复制）和备份恢复过程中，可能会增加网络传输和I&#x2F;O负担，导致延迟。</li>
<li><strong>查询优化</strong>：优化器在处理包含TEXT字段的查询时可能会选择效率较低的执行计划，因为无法准确估计TEXT字段的大小。</li>
<li><strong>排序和分组</strong>：如果查询需要对TEXT字段进行排序或分组，由于数据量大，可能会使用磁盘临时表，导致性能下降。</li>
<li><strong>应用场景不匹配</strong>：很多时候，开发者使用TEXT类型存储的数据实际上可能是一个有限长度的字符串（如地址、描述等），此时使用VARCHAR（有长度限制）更为合适，因为VARCHAR在存储和性能上通常更高效。</li>
</ol>
<p>当然，如果确实需要存储大文本（如文章内容、日志等），那么使用TEXT类型是合理的。但在不需要存储大文本的情况下，应优先选择VARCHAR等类型，并设置合适的长度限制。</p>
<p><strong>总结</strong>：在不需要存储大文本时，使用TEXT类型可能会带来性能、存储和功能上的限制，因此建议仅在必要时使用。</p>
<p><strong>建议</strong></p>
<table>
<thead>
<tr>
<th align="left"><strong>场景</strong></th>
<th align="left"><strong>推荐类型</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">短文本（&lt; 255 字符）</td>
<td align="left"><code>VARCHAR(n)</code></td>
</tr>
<tr>
<td align="left">中等文本（&lt; 64KB）</td>
<td align="left"><code>VARCHAR(65535)</code></td>
</tr>
<tr>
<td align="left">超大文本（&gt; 64KB）</td>
<td align="left"><code>TEXT</code>（或分表存储）</td>
</tr>
</tbody></table>
<h3 id="redo-log、binlog有什么区别"><a href="#redo-log、binlog有什么区别" class="headerlink" title="redo log、binlog有什么区别"></a>redo log、binlog有什么区别</h3><table>
<thead>
<tr>
<th align="left"><strong>特性</strong></th>
<th align="left"><strong>Redo Log (重做日志)</strong></th>
<th align="left"><strong>Binlog (二进制日志)</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>所属层级</strong></td>
<td align="left"><strong>InnoDB 存储引擎层</strong></td>
<td align="left"><strong>MySQL Server 层</strong></td>
</tr>
<tr>
<td align="left"><strong>主要目的</strong></td>
<td align="left"><strong>崩溃恢复</strong>：确保事务的持久性 (Durability)</td>
<td align="left"><strong>数据复制与恢复</strong>：主从复制、时间点恢复</td>
</tr>
<tr>
<td align="left"><strong>日志类型</strong></td>
<td align="left"><strong>物理日志</strong>：记录页面的物理修改</td>
<td align="left"><strong>逻辑日志</strong>：记录导致数据变化的 SQL 语句或行变化</td>
</tr>
<tr>
<td align="left"><strong>内容</strong></td>
<td align="left">在某个数据页上做了什么修改 (物理操作)</td>
<td align="left">执行了什么 SQL 语句 (Statement) 或哪些行被修改 (Row)</td>
</tr>
<tr>
<td align="left"><strong>写入时机</strong></td>
<td align="left"><strong>持续写入</strong>：事务进行中</td>
<td align="left"><strong>事务提交后</strong>：事务完成时才写入</td>
</tr>
<tr>
<td align="left"><strong>写入方式</strong></td>
<td align="left"><strong>顺序写入</strong> (循环文件)</td>
<td align="left"><strong>追加写入</strong> (文件序列)</td>
</tr>
<tr>
<td align="left"><strong>生命周期</strong></td>
<td align="left">数据刷盘后可覆盖 (循环使用)</td>
<td align="left">可长期保存 (需手动或策略清理)</td>
</tr>
<tr>
<td align="left"><strong>刷盘策略</strong></td>
<td align="left"><code>innodb_flush_log_at_trx_commit</code></td>
<td align="left"><code>sync_binlog</code></td>
</tr>
<tr>
<td align="left"><strong>必需性</strong></td>
<td align="left">InnoDB 必需，无法关闭</td>
<td align="left">可选择开启</td>
</tr>
<tr>
<td align="left"><strong>格式</strong></td>
<td align="left">InnoDB 私有格式</td>
<td align="left"><code>STATEMENT</code>, <code>ROW</code>, <code>MIXED</code></td>
</tr>
<tr>
<td align="left"><strong>使用场景</strong></td>
<td align="left">数据库崩溃后自动恢复未刷盘的数据</td>
<td align="left">主从复制、增量备份、时间点恢复、数据审计</td>
</tr>
</tbody></table>
<p><strong>日志内容与类型：</strong></p>
<ul>
<li><strong>Redo Log (物理日志):</strong> 记录的是物理级别的更改。它描述的是“在某个数据页 (Page) 上的某个偏移量处做了什么修改”。例如：“在表空间 ID 为 X，页号 Y 的数据页上，偏移量 Z 开始的 4 个字节被修改为值 0x12345678”。它不关心具体的 SQL 语句是什么，只关心数据页的物理变化。这种日志体积通常较小且高效。</li>
<li><strong>Binlog (逻辑日志):</strong> 记录的是逻辑级别的操作。根据 binlog 格式 (<code>STATEMENT</code>, <code>ROW</code>, <code>MIXED</code>) 的不同，它记录的内容也不同：<ul>
<li><code>STATEMENT</code>: 记录原始的 SQL 语句本身（如 <code>UPDATE users SET balance=100 WHERE id=5;</code>）。</li>
<li><code>ROW</code>: 记录被修改的行在修改前和修改后的数据（或仅修改后的数据，取决于配置）。例如，记录 <code>id=5</code> 的这行数据，<code>balance</code> 字段从 <code>50</code> 改成了 <code>100</code>。</li>
<li><code>MIXED</code>: 混合模式，默认使用 <code>STATEMENT</code>，但在某些可能引起主从不一致（如使用非确定性函数 <code>UUID()</code>, <code>NOW()</code>）的情况下自动切换到 <code>ROW</code>。逻辑日志更易于人类理解和用于复制，但 <code>ROW</code> 模式在批量操作时可能产生大量日志。</li>
</ul>
</li>
</ul>
<p><strong>写入时机：</strong></p>
<ul>
<li><strong>Redo Log:</strong> 在事务执行过程中 <strong>持续写入</strong>。当事务修改数据时，首先会在内存中的 Buffer Pool 修改数据页（产生脏页），同时会生成对应的 redo log 记录并 <strong>顺序、近乎实时地写入 redo log buffer</strong>，然后根据策略（<code>innodb_flush_log_at_trx_commit</code>）刷写到磁盘上的 redo log 文件。<strong>事务提交时，必须确保其对应的 redo log 已按策略持久化到磁盘</strong>，这是保证持久性的关键。</li>
<li><strong>Binlog:</strong> 是在事务 <strong>提交完成之前</strong>，但在确保 redo log 已持久化之后（见两阶段提交）<strong>一次性写入</strong>。事务提交时，MySQL Server 层将事务涉及的所有 binlog 事件按顺序写入 binlog cache，然后根据策略 (<code>sync_binlog</code>) 刷写到磁盘上的 binlog 文件。<strong>只有 binlog 成功写入并持久化（根据策略），事务才被认为最终提交成功</strong>。</li>
</ul>
<p><strong>持久化策略 (刷盘控制)：</strong></p>
<ul>
<li><strong>Redo Log:</strong> 由参数 <code>innodb_flush_log_at_trx_commit</code> 控制：<ul>
<li><code>0</code>: 每秒写入并刷盘一次（可能丢失最多1秒的事务）。</li>
<li><code>1</code>: <strong>默认且最安全</strong>。每次事务提交时写入并刷盘（保证崩溃后不丢数据）。</li>
<li><code>2</code>: 每次事务提交时写入 OS 缓存，每秒刷盘一次（MySQL 进程崩溃不丢数据，OS 崩溃可能丢失最多1秒的事务）。</li>
</ul>
</li>
<li><strong>Binlog:</strong> 由参数 <code>sync_binlog</code> 控制：<ul>
<li><code>0</code>: 依赖 OS 刷新，MySQL 不主动刷盘（性能最好，风险最高）。</li>
<li><code>1</code>: <strong>默认且安全</strong>。每次事务提交后都刷盘（保证 binlog 不丢失）。</li>
<li><code>N</code> (N&gt;1): 每 N 个事务提交后刷盘一次（折中方案）。</li>
</ul>
</li>
</ul>
<p><strong>两阶段提交 (2PC - Two-Phase Commit)：</strong><br>为了保证 redo log 和 binlog 逻辑上的一致性（即：一个事务在 redo log 中 prepare 了，那么在 binlog 中必须完整存在；反之，如果一个事务在 binlog 中存在，那么在 redo log 中必须 commit），InnoDB 和 MySQL Server 层使用了 <strong>两阶段提交</strong> 机制：</p>
<ol>
<li><strong>Prepare 阶段：</strong> InnoDB 将事务的 redo log 写入磁盘并标记为 <code>PREPARE</code> 状态。此时事务在引擎层已“准备就绪”。</li>
<li><strong>Write &amp; Sync Binlog 阶段：</strong> MySQL Server 将事务的 binlog 写入磁盘（根据 <code>sync_binlog</code> 策略决定是否刷盘）。</li>
<li><strong>Commit 阶段 (InnoDB)：</strong> 如果 binlog 写入成功，MySQL Server 通知 InnoDB。InnoDB 将 redo log 中该事务的状态标记为 <code>COMMIT</code>（这是一个非常快速的标记操作）。此时事务在引擎层正式提交。如果 binlog 写入失败，则通知 InnoDB 回滚该事务。<br>这个机制确保了：即使数据库在提交过程中崩溃，恢复时也能根据 redo log 和 binlog 的状态决定事务是提交还是回滚，从而保证数据在主库和从库上的一致性。</li>
</ol>
<h3 id="什么是刷盘"><a href="#什么是刷盘" class="headerlink" title="什么是刷盘"></a>什么是刷盘</h3><p>“刷盘”是数据库领域一个极其重要的操作，指的是 <strong>将内存中的数据强制写入（并确保同步到）物理磁盘存储设备的过程</strong>。</p>
<ul>
<li><strong>刷盘做了什么？</strong><ul>
<li><strong>写入 (Write)：</strong> 操作系统将内存缓冲区（如 redo log buffer, binlog cache）中的数据复制到磁盘驱动器的 <strong>操作系统缓存 (OS Page Cache)</strong> 中。这一步通常很快，因为只是内存间的拷贝。</li>
<li><strong>同步&#x2F;刷新 (Sync &#x2F; Flush &#x2F; Fsync)：</strong> <strong>这才是“刷盘”的核心和代价所在！</strong> 它要求操作系统 <strong>强制</strong> 将操作系统缓存中特定文件的数据 <strong>真正写入物理磁盘的存储介质</strong>（如 SSD&#x2F;HDD 的闪存颗粒&#x2F;盘片）上，并等待磁盘确认写入完成。这个操作涉及到物理 I&#x2F;O，速度相对内存操作慢几个数量级，是数据库操作的主要性能瓶颈之一。<code>fsync()</code> 是 Unix&#x2F;Linux 系统中用来执行这个强制同步操作的标准系统调用。</li>
</ul>
</li>
<li><strong>刷盘策略的权衡：</strong> 因为 <code>fsync()</code> 非常慢：<ul>
<li>如果每次事务提交都强制刷盘 (<code>fsync</code>)，能最大程度保证数据不丢失（安全性最高），但性能最差（吞吐量低，延迟高）。</li>
<li>如果累积多个事务或隔一段时间再刷盘，性能会提升（吞吐量高，延迟低），但如果在刷盘间隔内发生崩溃，未刷盘的数据就会丢失（安全性降低）。</li>
<li>数据库通过参数（如 <code>innodb_flush_log_at_trx_commit</code>, <code>sync_binlog</code>）让你在这两者之间进行 <strong>权衡（Trade-off）</strong>。</li>
</ul>
</li>
</ul>
<h3 id="buffer-pool和change-buffer有什么区别"><a href="#buffer-pool和change-buffer有什么区别" class="headerlink" title="buffer pool和change buffer有什么区别"></a>buffer pool和change buffer有什么区别</h3><p>在 MySQL 的 InnoDB 存储引擎中，<strong>Change Buffer</strong> 和 <strong>Buffer Pool</strong> 都是核心的内存结构，用于优化性能，但它们解决的问题和运作方式截然不同：</p>
<p><strong>1. Buffer Pool (缓冲池)</strong></p>
<ul>
<li><strong>本质：</strong> <strong>数据库的主内存缓存区域</strong>。它是 InnoDB 用于缓存从磁盘读取的<strong>数据页（Data Pages）和索引页（Index Pages）</strong> 的地方。</li>
<li><strong>目的：</strong> <strong>减少磁盘 I&#x2F;O</strong>。当 InnoDB 需要访问数据（无论是读取还是修改）时，它首先检查所需的数据页是否已经在 Buffer Pool 中。如果在（缓存命中），就直接在内存中操作，速度极快。如果不在（缓存未命中），就需要从磁盘读取相应的页加载到 Buffer Pool 中，然后再进行操作。</li>
<li><strong>作用对象：</strong> <strong>所有类型的数据页</strong>。包括：<ul>
<li>包含表行数据的页（数据页）。</li>
<li>包含索引（主键索引、二级索引）条目的页（索引页）。</li>
<li>系统页、Undo 页等。</li>
</ul>
</li>
<li><strong>工作原理：</strong><ul>
<li><strong>读操作：</strong> 优先从 Buffer Pool 读取，未命中则读磁盘并加载。</li>
<li><strong>写操作 (DML: INSERT, UPDATE, DELETE)：</strong><ol>
<li>修改发生在 Buffer Pool 中的<strong>脏页（Dirty Page）</strong>（已被修改但尚未写回磁盘的页）。</li>
<li>修改会写入 Redo Log（重做日志）以保证持久性。</li>
<li><strong>不是立即写回磁盘！</strong> Buffer Pool 中的脏页会在后台由专门的线程（如 <code>InnoDB Master Thread</code>）或根据特定策略（如 LRU 淘汰、检查点触发、Buffer Pool 空间不足时）<strong>异步刷新（Flush）</strong> 到磁盘的数据文件（.ibd 文件）。</li>
</ol>
</li>
</ul>
</li>
<li><strong>关键特性：</strong><ul>
<li><strong>核心缓存机制：</strong> 对数据库的整体性能（尤其是读性能）至关重要。</li>
<li><strong>管理策略：</strong> 使用 LRU（最近最少使用）等算法管理页的换入换出。</li>
<li><strong>大小可配置：</strong> 通过 <code>innodb_buffer_pool_size</code> 参数设置，通常是服务器总内存的 50%-80%。</li>
<li><strong>监控指标：</strong> <code>Innodb_buffer_pool_read_requests</code> (总请求数), <code>Innodb_buffer_pool_reads</code> (物理磁盘读次数)，命中率 &#x3D; <code>(1 - Innodb_buffer_pool_reads / Innodb_buffer_pool_read_requests) * 100%</code>。</li>
</ul>
</li>
</ul>
<p><strong>2. Change Buffer (更改缓冲区，旧称 Insert Buffer)</strong></p>
<ul>
<li><strong>本质：</strong> <strong>一种特殊的缓存结构，用于优化对非唯一二级索引的写操作（INSERT, UPDATE, DELETE）</strong>。它物理上<strong>是 Buffer Pool 的一部分</strong>，但逻辑功能独立。</li>
<li><strong>目的：</strong> <strong>减少对非唯一二级索引的随机磁盘 I&#x2F;O。</strong> 当修改操作（尤其是 INSERT 和 UPDATE）涉及到非唯一的二级索引时，如果对应的索引页<strong>不在 Buffer Pool</strong> 中，传统的做法是必须先将该索引页从磁盘读入 Buffer Pool 才能修改。Change Buffer 允许 InnoDB <strong>将这次修改“缓冲”下来</strong>，而不是立即去磁盘加载那个索引页。</li>
<li><strong>作用对象：</strong> <strong>仅限于非唯一二级索引（Non-Unique Secondary Index）</strong> 的修改操作。它不处理：<ul>
<li>主键索引（聚簇索引）的修改（直接在 Buffer Pool 中的页上修改）。</li>
<li>唯一索引的修改（需要立即检查唯一性约束，必须加载索引页）。</li>
<li>数据页本身的修改（在 Buffer Pool 中进行）。</li>
</ul>
</li>
<li><strong>工作原理：</strong><ul>
<li>当发生影响非唯一二级索引的 DML 操作时：<ol>
<li>检查目标索引页是否已在 Buffer Pool 中。</li>
<li><strong>如果在：</strong> 直接在内存中的索引页上进行修改。</li>
<li><strong>如果不在：</strong> <strong>将这次修改操作（包含索引列值、行标识等信息）记录到 Change Buffer 中</strong>，而不是去磁盘加载索引页。修改操作本身也会记录到 Redo Log。</li>
</ol>
</li>
<li><strong>后续操作（Merge 合并）：</strong><ul>
<li>当<strong>稍后</strong>需要读取这个被修改的索引页（例如通过 SELECT 使用该索引、后台 Purge 线程、Checkpoint 检查点、Server 空闲、Change Buffer 满、关闭数据库时），InnoDB 会先将该索引页从磁盘加载到 Buffer Pool。</li>
<li>加载完成后，InnoDB 会查找 Change Buffer 中所有针对这个<strong>已加载页</strong>的待处理修改记录。</li>
<li>将这些修改记录<strong>应用（Merge）</strong> 到新加载到内存的索引页上，使该索引页在内存中达到最新状态。</li>
<li>此时，被 Merge 的索引页变成了脏页，之后会由 Buffer Pool 的刷新机制写回磁盘。</li>
</ul>
</li>
</ul>
</li>
<li><strong>关键特性：</strong><ul>
<li><strong>写优化：</strong> 核心价值在于将潜在的多次随机磁盘 I&#x2F;O（加载索引页）<strong>延迟并合并</strong>。对于写密集型应用，特别是涉及大量非唯一二级索引插入&#x2F;更新的场景（如批量导入数据），性能提升显著（可能快数倍甚至十倍）。</li>
<li><strong>内存效率：</strong> 存储修改记录通常比缓存整个索引页占用空间小得多。</li>
<li><strong>适用场景限制：</strong> 只对非唯一二级索引有效。</li>
<li><strong>大小可配置：</strong> 通过 <code>innodb_change_buffer_max_size</code> 设置它占 Buffer Pool 总大小的百分比（默认 25%）。</li>
<li><strong>监控指标：</strong> <code>Ibuf: size</code>, <code>Ibuf: free list len</code>, <code>Ibuf: inserts</code>, <code>Ibuf: merged ops</code>, <code>Ibuf: merges</code> (在 <code>SHOW ENGINE INNODB STATUS</code> 输出中)。</li>
</ul>
</li>
</ul>
<p><strong>核心区别总结表</strong></p>
<table>
<thead>
<tr>
<th align="left">特性</th>
<th align="left">Buffer Pool (缓冲池)</th>
<th align="left">Change Buffer (更改缓冲区)</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>核心作用</strong></td>
<td align="left"><strong>数据库主内存缓存，缓存数据页和索引页</strong></td>
<td align="left"><strong>优化对非唯一二级索引的写操作</strong></td>
</tr>
<tr>
<td align="left"><strong>主要目的</strong></td>
<td align="left"><strong>减少磁盘读 I&#x2F;O (提升读性能)</strong></td>
<td align="left"><strong>减少磁盘随机写 I&#x2F;O (提升写性能，尤其非唯一索引插入&#x2F;更新)</strong></td>
</tr>
<tr>
<td align="left"><strong>作用对象</strong></td>
<td align="left"><strong>所有类型的数据页</strong> (数据页、索引页、系统页等)</td>
<td align="left"><strong>仅限非唯一二级索引页</strong>的修改操作</td>
</tr>
<tr>
<td align="left"><strong>操作类型</strong></td>
<td align="left"><strong>读 &amp; 写</strong> (修改发生在缓冲池中的脏页上)</td>
<td align="left"><strong>仅写</strong> (缓冲修改操作本身)</td>
</tr>
<tr>
<td align="left"><strong>修改处理位置</strong></td>
<td align="left">直接在内存中的目标页上修改</td>
<td align="left">将修改操作记录在 Change Buffer 中</td>
</tr>
<tr>
<td align="left"><strong>与磁盘交互</strong></td>
<td align="left">缓存页未命中时需读磁盘加载；脏页异步刷回磁盘</td>
<td align="left">避免立即加载不在内存的索引页；修改操作在 Merge 时才应用到内存页</td>
</tr>
<tr>
<td align="left"><strong>关键过程</strong></td>
<td align="left">LRU 管理、脏页刷新</td>
<td align="left">Merge (合并) - 将缓冲的修改应用到后来加载的索引页上</td>
</tr>
<tr>
<td align="left"><strong>物理位置</strong></td>
<td align="left">独立的内存区域</td>
<td align="left"><strong>物理上是 Buffer Pool 的一部分</strong></td>
</tr>
<tr>
<td align="left"><strong>配置参数</strong></td>
<td align="left"><code>innodb_buffer_pool_size</code></td>
<td align="left"><code>innodb_change_buffer_max_size</code></td>
</tr>
<tr>
<td align="left"><strong>典型优化场景</strong></td>
<td align="left">读密集型查询、热点数据访问</td>
<td align="left">写密集型操作、大量非唯一索引插入&#x2F;更新、批量导入</td>
</tr>
</tbody></table>
<p><strong>简单类比：</strong></p>
<ul>
<li><strong>Buffer Pool 像一个图书馆的阅览区：</strong> 把常用的书（数据页）从书库（磁盘）拿出来放在桌子上（内存），方便你（数据库线程）快速翻阅（读取）和做笔记（修改）。桌子空间有限，不常用的书会被放回书库。</li>
<li><strong>Change Buffer 像阅览区管理员的一个便签本：</strong> 当你（数据库线程）想在一本<strong>不在阅览区桌上</strong>的、属于某个特定类别（非唯一二级索引）的书上添加一条新信息（INSERT）或者修改一条信息（UPDATE）时，管理员不会马上去书库找那本厚厚的书搬出来放桌上让你改一页。而是让你把要添加&#x2F;修改的内容写在便签上（记录到 Change Buffer）。等以后有人需要看那本书（或管理员整理时），管理员才去书库把书拿出来放到桌上（加载索引页到 Buffer Pool），然后把便签上所有关于这本书的修改（Merge）贴到书里对应的位置（应用修改到内存页）。这样避免了频繁跑书库拿书只为改一个小地方。</li>
</ul>
<p><strong>总结：</strong></p>
<ul>
<li><strong>Buffer Pool 是基础缓存层，目标是加速对数据的访问（读和写），核心是管理数据页在内存中的驻留。</strong></li>
<li><strong>Change Buffer 是建立在 Buffer Pool 之上的一个针对特定场景（非唯一二级索引写）的高级优化，核心思想是延迟和合并对索引页的修改操作，以减少昂贵的随机磁盘 I&#x2F;O。</strong></li>
</ul>
<p>理解这两者的区别和协作对于深入掌握 InnoDB 的工作原理和进行 MySQL 性能调优至关重要。Buffer Pool 的命中率直接影响整体性能，而合理利用 Change Buffer 可以显著提升涉及非唯一索引的写入效率。</p>
<h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="Redis-有哪些数据类型，分别用于哪些场景"><a href="#Redis-有哪些数据类型，分别用于哪些场景" class="headerlink" title="Redis 有哪些数据类型，分别用于哪些场景"></a>Redis 有哪些数据类型，分别用于哪些场景</h3><p><strong>String（字符串）</strong></p>
<ul>
<li><strong>描述</strong>：最基本的数据类型，可存储文本、二进制数据（如图片）、数字（整数或浮点数）。</li>
<li><strong>典型场景</strong>：<ul>
<li><strong>缓存</strong>：存储用户会话信息（Session）、HTML片段、API响应等。</li>
<li><strong>计数器</strong>：网站访问量、点赞数、库存数量（利用 <code>INCR/DECR</code>）。</li>
<li><strong>分布式锁</strong>：通过 <code>SET key value NX EX</code> 实现简单锁。</li>
<li><strong>位操作（Bitmaps）</strong>：利用 <code>SETBIT</code>, <code>GETBIT</code>, <code>BITCOUNT</code> 等命令实现用户在线状态、签到记录、布隆过滤器等（本质上是操作字符串的位）。</li>
</ul>
</li>
</ul>
<p><strong>List（列表）</strong></p>
<ul>
<li><strong>描述</strong>：有序的字符串集合，元素可重复。按照插入顺序排序，可在头部(<code>LPUSH</code>)或尾部(<code>RPUSH</code>)插入元素。</li>
<li><strong>典型场景</strong>：<ul>
<li><strong>消息队列（简单版）</strong>：生产者 <code>LPUSH</code> 消息，消费者 <code>RPOP</code>&#x2F;<code>BRPOP</code> 消息（FIFO）。也可实现栈（LIFO）。</li>
<li><strong>最新消息&#x2F;动态流（Timeline）</strong>：<code>LPUSH</code> 最新内容，<code>LRANGE</code> 获取最近 N 条。</li>
<li><strong>记录操作日志</strong>。</li>
</ul>
</li>
</ul>
<p><strong>Set（集合）</strong></p>
<ul>
<li><strong>描述</strong>：无序的字符串集合，元素<strong>不可重复</strong>，支持集合运算（交集、并集、差集）。</li>
<li><strong>典型场景</strong>：<ul>
<li><strong>标签（Tagging）</strong>：存储文章、商品的标签（自动去重）。</li>
<li><strong>共同关注&#x2F;好友（社交关系）</strong>：利用 <code>SINTER</code> 求交集。</li>
</ul>
</li>
</ul>
<p><strong>Hash（哈希 &#x2F; 字典）</strong></p>
<ul>
<li><strong>描述</strong>：键值对集合，用于存储对象（如用户信息）。<code>field-value</code> 映射表。</li>
<li><strong>典型场景</strong>：<ul>
<li><strong>存储对象</strong>：用户信息（<code>user:1000 &#123;name: &quot;Alice&quot;, age: 30, email: ...&#125;</code>）、商品详情、配置项。</li>
<li><strong>频繁修改部分属性的对象</strong>：如只更新用户积分，避免读取整个字符串再写回。</li>
</ul>
</li>
</ul>
<p><strong>Sorted Set（有序集合 &#x2F; ZSet）</strong></p>
<ul>
<li><strong>描述</strong>：Set 的升级版，元素<strong>唯一</strong>，但每个元素关联一个 <code>score</code>（分数）。元素<strong>按 <code>score</code> 排序</strong>（从小到大）。<code>score</code> 可相同，此时按元素字典序排序。</li>
<li><strong>典型场景</strong>：<ul>
<li><strong>排行榜</strong>：游戏积分榜（<code>score</code> 为积分）、热搜榜（<code>score</code> 为热度值）。<code>ZREVRANGE</code> 获取 Top N。</li>
</ul>
</li>
</ul>
<p><strong>Bitmaps</strong></p>
<ul>
<li><strong>本质</strong>：String 类型的位操作扩展。</li>
<li><strong>场景</strong>：极省空间的布尔值统计（用户在线状态、每日签到、活跃用户统计、布隆过滤器）。</li>
</ul>
<p><strong>HyperLogLog（HLL）</strong></p>
<ul>
<li><strong>本质</strong>：特殊的 String 类型。</li>
<li><strong>场景</strong>：海量数据的去重计数（网站 UV、独立 IP 访问数、搜索词去重统计），不需要精确结果时。</li>
</ul>
<p><strong>Geospatial（地理空间）</strong></p>
<ul>
<li><strong>本质</strong>：基于 Sorted Set（ZSet）实现，<code>member</code> 是位置标识符，<code>score</code> 是经度+纬度编码成的 52 位整数（GeoHash）。</li>
<li><strong>场景</strong>：附近的人&#x2F;地点（如滴滴打车）、基于位置的服务（LBS）、地理围栏。</li>
</ul>
<p><strong>Streams</strong></p>
<ul>
<li><strong>描述</strong>：Redis 5.0 引入。为<strong>消息队列</strong>设计的功能更完善的数据类型。类似 Kafka 或 RabbitMQ 的 topic。</li>
<li><strong>场景</strong>：<strong>可靠的消息队列</strong>、事件溯源（Event Sourcing）、实时数据管道。</li>
</ul>
<h3 id="Redis为什么快？单线程如何处理高并发？"><a href="#Redis为什么快？单线程如何处理高并发？" class="headerlink" title="Redis为什么快？单线程如何处理高并发？"></a>Redis为什么快？单线程如何处理高并发？</h3><p>对于Redis的高性能设计，我的理解主要得益于以下几点：</p>
<ul>
<li><p>内存操作：Redis数据存储在内存，相比于磁盘数据库，减少了IO开销</p>
</li>
<li><p>高效的数据结构：Redis针对不同场景设计了不同的数据结构，优化了空间和访问效率</p>
</li>
<li><p>单线程：Redis使用单线程处理命令，避免了多线程之间的竞争和上下文切换的开销</p>
</li>
<li><p>IO多路复用：Redis基于epoll&#x2F;kqueue实现了非阻塞的网络模型，通过事件机制循环处理请求</p>
</li>
</ul>
<h3 id="Redis和MySQL的区别"><a href="#Redis和MySQL的区别" class="headerlink" title="Redis和MySQL的区别"></a>Redis和MySQL的区别</h3><table>
<thead>
<tr>
<th></th>
<th>Redis</th>
<th>MySQL</th>
</tr>
</thead>
<tbody><tr>
<td>数据结构</td>
<td>非结构化</td>
<td>结构化</td>
</tr>
<tr>
<td>持久化</td>
<td>可选持久化</td>
<td>默认持久化</td>
</tr>
<tr>
<td>事务支持</td>
<td>简单支持</td>
<td>支持完整的ACID</td>
</tr>
<tr>
<td>扩展性</td>
<td>通过分片水平扩展</td>
<td>复杂，需分库分表或中间件</td>
</tr>
<tr>
<td>数据一致性</td>
<td>最终一致性</td>
<td>强一致性</td>
</tr>
</tbody></table>
<p>总结：</p>
<ul>
<li>当需要复杂查询和事务支持，对数据一致性要求较高，需要长期持久化存储的场景，选择MySQL</li>
<li>当需要超高性能和灵活数据类型，对数据的一致性要求不那么高，且容忍一定的数据丢失的情况下，选择Redis</li>
</ul>
<h3 id="Redis和memchahed的区别"><a href="#Redis和memchahed的区别" class="headerlink" title="Redis和memchahed的区别"></a>Redis和memchahed的区别</h3><table>
<thead>
<tr>
<th></th>
<th>Redis</th>
<th>Memcached</th>
</tr>
</thead>
<tbody><tr>
<td>数据类型</td>
<td>丰富的数据类型：string、hash、list等</td>
<td>只支持string</td>
</tr>
<tr>
<td>持久化</td>
<td>支持（RDB、AOF）</td>
<td>不支持</td>
</tr>
<tr>
<td>事务</td>
<td>简单支持（MULTI&#x2F;EXEC）</td>
<td>不支持</td>
</tr>
<tr>
<td>分布式</td>
<td>支持，集群自动分片</td>
<td>依赖客户端一致性哈希或第三方工具实现分布式</td>
</tr>
<tr>
<td>命令</td>
<td>支持丰富的命令</td>
<td>仅支持SET、GET、ADD、DELTE等基础操作</td>
</tr>
<tr>
<td>内存占用</td>
<td>复杂数据结构可能导致内存消耗较高</td>
<td>内存利用率高，但灵活性较低</td>
</tr>
</tbody></table>
<p>总结：</p>
<ul>
<li>需要复杂数据结构、持久化、事务支持和高可用性的场景，选择Redis</li>
<li>追求极致的性能和简单性，数据结构简单且无需持久化的场景，可以选择Memcached</li>
</ul>
<h3 id="Redis-IO多路复用"><a href="#Redis-IO多路复用" class="headerlink" title="Redis IO多路复用"></a>Redis IO多路复用</h3><p>常见的 I&#x2F;O 多路复用机制包括 select、poll 和 epoll 等。</p>
<table>
<thead>
<tr>
<th>特性</th>
<th><code>select</code></th>
<th><code>poll</code></th>
<th><code>epoll</code></th>
</tr>
</thead>
<tbody><tr>
<td>文件描述符限制</td>
<td>受 <code>FD_SETSIZE</code> 限制</td>
<td>无限制</td>
<td>无限制</td>
</tr>
<tr>
<td>时间复杂度</td>
<td>O(n)</td>
<td>O(n)</td>
<td>O(1)</td>
</tr>
<tr>
<td>数据复制</td>
<td>需要</td>
<td>需要</td>
<td>不需要</td>
</tr>
<tr>
<td>工作方式</td>
<td>线性扫描</td>
<td>线性扫描</td>
<td>事件通知</td>
</tr>
<tr>
<td>内核支持</td>
<td>所有 UNIX 系统</td>
<td>所有 UNIX 系统</td>
<td>Linux 2.6 及以上版本</td>
</tr>
<tr>
<td>适用场景</td>
<td>少量连接</td>
<td>中等连接</td>
<td>大量并发连接</td>
</tr>
</tbody></table>
<p><img src="https://cdn.tobebetterjavaer.com/stutymore/redis-20240918114125.png" alt="有盐先生：IO 多路复用"></p>
<h3 id="Redis-6-0-多线程"><a href="#Redis-6-0-多线程" class="headerlink" title="Redis 6.0 多线程"></a>Redis 6.0 多线程</h3><p>在 Redis 6.0 中，多线程主要用来处理网络 IO 操作，命令解析和执行仍然是单线程完成，这样既可以发挥多核 CPU 的优势，又能避免锁和上下文切换带来的性能损耗。</p>
<p><img src="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/redis-b7b24e25-d2dc-4457-994f-95bdb3674b8e.png" alt="三分恶面渣逆袭：Redis6.0多线程"></p>
<h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">Redis核心知识脑图</span><br><span class="line">├── 数据结构篇</span><br><span class="line">│   ├── 基础数据结构</span><br><span class="line">│   │   ├── String</span><br><span class="line">│   │   │   ├── 二进制安全</span><br><span class="line">│   │   │   ├── 应用场景：缓存、计数器</span><br><span class="line">│   │   ├── List</span><br><span class="line">│   │   │   ├── 双向链表/ziplist</span><br><span class="line">│   │   │   ├── 应用场景：队列、栈</span><br><span class="line">│   │   ├── Hash</span><br><span class="line">│   │   │   ├── field-value结构</span><br><span class="line">│   │   │   ├── 应用场景：对象存储</span><br><span class="line">│   │   ├── Set</span><br><span class="line">│   │   │   ├── 无序唯一集合</span><br><span class="line">│   │   │   ├── 应用场景：标签系统</span><br><span class="line">│   │   └── Sorted Set</span><br><span class="line">│   │       ├── 带权重的Set</span><br><span class="line">│   │       └── 应用场景：排行榜</span><br><span class="line">│   └── 高级数据结构</span><br><span class="line">│       ├── HyperLogLog</span><br><span class="line">│       │   └── 基数统计（误差0.81%）</span><br><span class="line">│       ├── Bitmap</span><br><span class="line">│       │   └── 位操作（日活统计）</span><br><span class="line">│       ├── Geospatial</span><br><span class="line">│       │   └── 地理位置计算</span><br><span class="line">│       └── Streams</span><br><span class="line">│           └── 消息队列（类似Kafka）</span><br><span class="line">│</span><br><span class="line">└── 内存管理篇</span><br><span class="line">    ├── 内存分配</span><br><span class="line">    │   ├── 使用jemalloc库</span><br><span class="line">    │   └── 预分配策略</span><br><span class="line">    ├── 内存回收</span><br><span class="line">    │   ├── 惰性删除（访问时检查过期）</span><br><span class="line">    │   └── 定期删除（随机抽查）</span><br><span class="line">    ├── 内存优化</span><br><span class="line">    │   ├── 编码优化</span><br><span class="line">    │   │   ├── ziplist（小数据量）</span><br><span class="line">    │   │   ├── intset（整数集合）</span><br><span class="line">    │   ├── 共享对象（0-9999整数池）</span><br><span class="line">    │   └── 内存碎片处理</span><br><span class="line">    │       ├── info memory查看碎片率</span><br><span class="line">    │       └── 重启消除碎片</span><br><span class="line">    ├── 淘汰策略</span><br><span class="line">    │   ├── volatile-lru</span><br><span class="line">    │   ├── allkeys-lru</span><br><span class="line">    │   ├── volatile-lfu（4.0+）</span><br><span class="line">    │   ├── allkeys-random</span><br><span class="line">    │   └── noeviction（默认）</span><br><span class="line">    └── 内存监控</span><br><span class="line">        ├── info memory命令</span><br><span class="line">        ├── used_memory_human</span><br><span class="line">        └── CONFIG SET调整参数</span><br></pre></td></tr></table></figure>

<h2 id="IO模型"><a href="#IO模型" class="headerlink" title="IO模型"></a>IO模型</h2><h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><h3 id="什么是缓存穿透-雪崩-击穿，对应的解决方案是什么"><a href="#什么是缓存穿透-雪崩-击穿，对应的解决方案是什么" class="headerlink" title="什么是缓存穿透&#x2F;雪崩&#x2F;击穿，对应的解决方案是什么"></a>什么是缓存穿透&#x2F;雪崩&#x2F;击穿，对应的解决方案是什么</h3><p><strong>缓存穿透</strong>是指查询数据库中不存在的数据，导致请求每次都穿过缓存查询数据库。</p>
<p>解决方案：</p>
<ul>
<li><strong>布隆过滤器（Bloom Filter）</strong></li>
</ul>
<p>服务启动时加载全量有效key，标记数据是否存在；新增数据时同步更新过滤器</p>
<p>缺点：存在一定的误判率</p>
<ul>
<li><strong>缓存空值</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Object <span class="title function_">getData</span><span class="params">(String key)</span> &#123;</span><br><span class="line">    <span class="type">Object</span> <span class="variable">value</span> <span class="operator">=</span> redis.get(key);</span><br><span class="line">    <span class="keyword">if</span> (value != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (value <span class="keyword">instanceof</span> NullValue) &#123; <span class="comment">// 空值标记</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;</span><br><span class="line">    value = db.query(key);</span><br><span class="line">    <span class="keyword">if</span> (value == <span class="literal">null</span>) &#123;</span><br><span class="line">        redis.setex(key, <span class="number">300</span>, <span class="keyword">new</span> <span class="title class_">NullValue</span>()); <span class="comment">// 缓存空值5分钟</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        redis.setex(key, <span class="number">3600</span>, value); <span class="comment">// 正常缓存1小时</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>增强请求参数的复杂度，避免被猜测，同时做好数据的基础格式校验</li>
</ul>
<p><strong>缓存雪崩</strong>是指<strong>大量key</strong>同时失效，导致大量请求都去查询数据库，造成数据库压力骤增。</p>
<p>解决方案：</p>
<ul>
<li><strong>差异化过期时间</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 基础过期时间，1小时</span></span><br><span class="line"><span class="type">int</span> <span class="variable">baseExpire</span> <span class="operator">=</span> <span class="number">3600</span>;</span><br><span class="line"><span class="comment">// 随机0-5分钟</span></span><br><span class="line"><span class="type">int</span> <span class="variable">randomExpire</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Random</span>().nextInt(<span class="number">300</span>);</span><br><span class="line">redis.setex(key, baseExpire + randomExpire, value);</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>永不过期+异步更新</strong></li>
<li><strong>添加降级限流策略</strong></li>
<li><strong>添加多级缓存</strong></li>
</ul>
<p><strong>缓存击穿</strong>是指某个<strong>热点key</strong>失效的瞬间，有大量请求同时访问这个key，导致所有请求都去查询数据库。</p>
<p>解决方案：</p>
<ul>
<li><strong>互斥锁</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">RLock</span> <span class="variable">lock</span> <span class="operator">=</span> Redission.getLock(<span class="string">&quot;PREFIX:&quot;</span> + key);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (lock.tryLock(<span class="number">3</span>, <span class="number">30</span>, TimeUnit.SECONDS)) &#123;</span><br><span class="line">        <span class="comment">// 查库并重建缓存</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    lock.unlock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>逻辑过期</strong></li>
</ul>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="string">&quot;真实数据&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;expire_ts&quot;</span><span class="punctuation">:</span> <span class="number">1672502400</span> <span class="comment">// 逻辑过期时间戳</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>处理流程：</p>
<ol>
<li>判断逻辑过期时间<ol>
<li>未过期，直接返回数据</li>
<li>已过期，创建子线程，异步重建缓存</li>
</ol>
</li>
</ol>
<table>
<thead>
<tr>
<th>解决方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>互斥锁</td>
<td>实现简单；保证一致性；无需消耗额外内存</td>
<td>线程需等待，影响性能</td>
</tr>
<tr>
<td>逻辑过期</td>
<td>线程无需等待，性能较好</td>
<td>存在不一致性；消耗额外内存；实现复杂</td>
</tr>
</tbody></table>
<h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>布隆过滤器（Bloom Filter）是一种空间高效、快速判断某个元素是否存在于集合中的数据结构。它由布隆于1970年提出，主要用于大规模数据集合的快速查找和去重。</p>
<p>布隆过滤器的基本思想是使用多个独立的哈希函数将元素映射到一个位数组（或称为布隆过滤器的位向量）中，并将这些位数组初始化为0。当要插入一个元素时，通过这些哈希函数计算得到的多个哈希值对应的位都被设置为1。当要查询一个元素是否存在时，同样通过这些哈希函数计算得到的多个哈希值对应的位都被检查，如果其中有任意一个位为0，则表示元素一定不存在；如果所有位都为1，则表示元素可能存在，但并不一定存在，可能会存在一定的误判率。</p>
<p>布隆过滤器的优点是占用空间小，插入和查询操作的时间复杂度都是O(k)，其中k是哈希函数的数量。此外，布隆过滤器可以处理非常大的数据集合，而且对于插入和查询操作的响应速度非常快。然而，布隆过滤器的缺点是存在一定的误判率，即在查询时可能会出现”误判为存在”的情况，因此在使用时需要注意选择合适的哈希函数数量和位数组大小，以及合理设置误判率的阈值。</p>
<p>布隆过滤器在实际应用中有很多用途，例如在数据库、缓存、网络路由器、爬虫等领域中都有广泛的应用，特别是在处理大规模数据集合时，可以显著减少存储和查询的开销。但需要注意的是，布隆过滤器并不适用于所有情况，因为它存在一定的误判率，并且无法删除已插入的元素，因此在选择使用时需要根据具体应用场景进行评估。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.BitSet;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.security.MessageDigest;</span><br><span class="line"><span class="keyword">import</span> java.security.NoSuchAlgorithmException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BloomFilter</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> BitSet bitArray;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> m; <span class="comment">// 位数组的大小</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> k; <span class="comment">// 哈希函数的数量</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">BloomFilter</span><span class="params">(<span class="type">int</span> m, <span class="type">int</span> k)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.m = m;</span><br><span class="line">        <span class="built_in">this</span>.k = k;</span><br><span class="line">        <span class="built_in">this</span>.bitArray = <span class="keyword">new</span> <span class="title class_">BitSet</span>(m);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span>[] hash(String data) &#123;</span><br><span class="line">        <span class="type">int</span>[] hashValues = <span class="keyword">new</span> <span class="title class_">int</span>[k];</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">MessageDigest</span> <span class="variable">md</span> <span class="operator">=</span> MessageDigest.getInstance(<span class="string">&quot;SHA-256&quot;</span>);</span><br><span class="line">            <span class="type">byte</span>[] hashBytes = md.digest(data.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; k; i++) &#123;</span><br><span class="line">                hashValues[i] = Math.abs((<span class="type">int</span>) (hashBytes[(i * <span class="number">4</span>) % hashBytes.length]) % m);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> hashValues;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">insert</span><span class="params">(String data)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[] hashValues = hash(data);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> hashValue : hashValues) &#123;</span><br><span class="line">            bitArray.set(hashValue);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">query</span><span class="params">(String data)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[] hashValues = hash(data);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> hashValue : hashValues) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!bitArray.get(hashValue)) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 创建布隆过滤器，位数组大小为100，哈希函数数量为3</span></span><br><span class="line">        <span class="type">BloomFilter</span> <span class="variable">bloomFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BloomFilter</span>(<span class="number">100</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 插入元素</span></span><br><span class="line">        bloomFilter.insert(<span class="string">&quot;apple&quot;</span>);</span><br><span class="line">        bloomFilter.insert(<span class="string">&quot;banana&quot;</span>);</span><br><span class="line">        bloomFilter.insert(<span class="string">&quot;cherry&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 查询元素是否存在</span></span><br><span class="line">        System.out.println(bloomFilter.query(<span class="string">&quot;apple&quot;</span>)); <span class="comment">// true</span></span><br><span class="line">        System.out.println(bloomFilter.query(<span class="string">&quot;grape&quot;</span>)); <span class="comment">// false</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="缓存淘汰策略"><a href="#缓存淘汰策略" class="headerlink" title="缓存淘汰策略"></a>缓存淘汰策略</h3><table>
<thead>
<tr>
<th align="left"><strong>数据范围</strong></th>
<th align="left"><strong>策略</strong></th>
<th align="left"><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>所有Key</strong></td>
<td align="left"><code>allkeys-lru</code></td>
<td align="left">从所有Key中淘汰最近最少使用的</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>allkeys-lfu</code></td>
<td align="left">从所有Key中淘汰最不经常使用的（Redis 4.0+）</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>allkeys-random</code></td>
<td align="left">从所有Key中随机淘汰</td>
</tr>
<tr>
<td align="left"><strong>过期Key</strong></td>
<td align="left"><code>volatile-lru</code></td>
<td align="left">从设置了过期时间的Key中淘汰最近最少使用的</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>volatile-lfu</code></td>
<td align="left">从设置了过期时间的Key中淘汰最不经常使用的</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>volatile-random</code></td>
<td align="left">从设置了过期时间的Key中随机淘汰</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>volatile-ttl</code></td>
<td align="left">淘汰剩余存活时间（TTL）最短的Key</td>
</tr>
<tr>
<td align="left"><strong>不淘汰</strong></td>
<td align="left"><code>noeviction</code>（默认）</td>
<td align="left">内存不足时拒绝写入，返回错误</td>
</tr>
</tbody></table>
<h3 id="缓存与数据的更新策略"><a href="#缓存与数据的更新策略" class="headerlink" title="缓存与数据的更新策略"></a>缓存与数据的更新策略</h3><p><strong>方案一：先删缓存 → 更新数据库 → 重建缓存</strong></p>
<p><strong>问题风险</strong>：</p>
<ol>
<li><strong>并发脏读（严重问题）</strong><ul>
<li>线程A删除缓存后，尚未更新数据库</li>
<li>线程B读取缓存未命中，<strong>从数据库读到旧值</strong>并重建缓存</li>
<li>线程A更新数据库后，缓存中遗留<strong>旧数据</strong>（直到下次更新&#x2F;过期）<br><em>👉 缓存与数据库长期不一致</em></li>
</ul>
</li>
<li><strong>缓存击穿压力</strong><ul>
<li>删除缓存后，大量请求瞬间穿透到数据库（尤其热点数据）</li>
<li>若重建缓存慢，可能导致数据库雪崩</li>
</ul>
</li>
</ol>
<p><strong>方案二：先更新数据库 → 删除缓存（推荐方案）</strong></p>
<p><strong>问题风险：</strong></p>
<ol>
<li><strong>极小概率的旧数据残留</strong><ul>
<li>线程A读缓存<strong>命中旧值</strong>（此时缓存未失效）</li>
<li>线程B更新数据库并<strong>删除缓存</strong></li>
<li>线程A仍使用旧数据（短暂不一致，通常毫秒级）<br><em>👉 概率低，且旧数据很快被淘汰</em></li>
</ul>
</li>
<li><strong>缓存删除失败</strong><ul>
<li>数据库更新成功，但缓存删除失败 → <strong>永久不一致</strong><br><em>👉 需引入重试或补偿机制</em></li>
</ul>
</li>
</ol>
<p><strong>业界通用方案：Cache-Aside + 延迟双删</strong></p>
<p>结合可靠性设计，核心流程：</p>
<img src="/post/32511a71/image-20250807221917345.png" class="" title="image-20250807221917345">

<p><strong>关键优化措施</strong>：</p>
<ol>
<li><strong>延迟双删 (Double Delete)</strong><ul>
<li>更新数据库后<strong>立即删除缓存</strong></li>
<li><strong>额外启动异步任务</strong>（如延迟500ms）<strong>再次删除缓存</strong><br><em>👉 解决并发导致的旧数据重建问题</em></li>
</ul>
</li>
<li><strong>缓存操作失败重试</strong><ul>
<li>将删除操作发到<strong>消息队列</strong>（如Kafka&#x2F;RabbitMQ）</li>
<li>消费失败自动重试，直至成功<br><em>👉 确保最终一致性</em></li>
</ul>
</li>
<li><strong>短过期时间兜底</strong><ul>
<li>所有缓存设置 <strong>TTL（如1-5秒）</strong><br><em>👉 即使双删失败，旧数据也会快速过期</em></li>
</ul>
</li>
</ol>
<h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><h3 id="RDB和AOF持久化原理及优劣对比"><a href="#RDB和AOF持久化原理及优劣对比" class="headerlink" title="RDB和AOF持久化原理及优劣对比"></a>RDB和AOF持久化原理及优劣对比</h3><p>RDB，存储某一时刻内存中所有的数据，触发命令<code>save</code>、<code>bgsave</code>，主进程<code>fork</code>子进程，阻塞。</p>
<p>触发条件：</p>
<ol>
<li>客户端发送<code>shutdown</code></li>
<li>从节点要进行全量复制</li>
<li>达到<code>redis.conf</code>文件中配置的条件</li>
<li>客户端执行<code>flushall</code>（生成空的<code>dump.rdb</code>，慎用）</li>
</ol>
<p>不能频繁生成 RBD 快照，原因：</p>
<ul>
<li>多次 RDB 会竞争磁盘带宽</li>
<li><code>fork</code> 子进程会阻塞主进程</li>
</ul>
<p>写时复制<code>copy-on-write</code>：</p>
<ul>
<li><strong>共享内存初始化</strong>：子进程刚创建时，<strong>与父进程共享全部内存页</strong>，此时内存占用几乎无额外开销。</li>
<li><strong>写操作触发复制</strong>：若父进程收到写请求（修改数据），操作系统会<strong>将被修改的内存页复制一份</strong>，父进程在副本上修改，子进程仍读取原始页。</li>
<li><strong>子进程视角固定</strong>：子进程看到的数据始终是 <code>fork()</code> 瞬间的状态，确保快照一致性。</li>
</ul>
<p>AOF，所有写命令追加到 <code>aof_buf</code>，刷盘策略由 <code>appendfsync</code> 决定。</p>
<p>如果有 AOF 文件，加载 AOF；否则，加载 RDB 文件。AOF 最多丢失 1s 数据。</p>
<p>AOF重写是直接为当前内存的数据生成对应命令，并不是读取旧AOF文件进行命令合并</p>
<ul>
<li>父子进程写同一个文件会产生竞争问题，影响父进程的性能。</li>
<li>如果AOF重写过程中失败了，相当于污染了原本的AOF文件，无法做恢复数据使用</li>
</ul>
<p>修复已损害的AOF文件：<code>redis-check-aof --fix appendonly.aof</code></p>
<table>
<thead>
<tr>
<th></th>
<th>RDB</th>
<th>AOF</th>
</tr>
</thead>
<tbody><tr>
<td>启动加载优先级</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td>体积</td>
<td>小</td>
<td>大</td>
</tr>
<tr>
<td>恢复速度</td>
<td>慢</td>
<td>快</td>
</tr>
</tbody></table>
<p>总结：RDB适合用作数据备份，AOF适合用作数据恢复。</p>
<h3 id="全量同步和增量同步的区别"><a href="#全量同步和增量同步的区别" class="headerlink" title="全量同步和增量同步的区别"></a>全量同步和增量同步的区别</h3><p>全量同步：master生成当前内存中所有数据的RDB文件，将RDB发送给slave。在此过程中，master将新的命令记录在<code>repl_backlog</code>中，后续再发送给slave。</p>
<p>执行时机：</p>
<ol>
<li>slave第一次连接到master</li>
<li>slave宕机太久，导致它在<code>repl_backlog</code>中的<code>offset</code>已经被覆盖掉了</li>
</ol>
<p>增量同步：salve将自己的<code>offset</code>发送到master，master将<code>repl_backlog</code>中<code>offset</code>之后的命令发送给slave</p>
<p>执行时机：</p>
<ol>
<li>slave断开重连之后，<code>repl_backlog</code>中的<code>offset</code>尚未被覆盖</li>
</ol>
<h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><h3 id="Redis分布式锁实现"><a href="#Redis分布式锁实现" class="headerlink" title="Redis分布式锁实现"></a>Redis分布式锁实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.data.redis.core.RedisTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.core.ValueOperations;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RedisDistributedLock</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">LOCK_KEY</span> <span class="operator">=</span> <span class="string">&quot;myLock&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">LOCK_EXPIRE_TIME</span> <span class="operator">=</span> <span class="number">5000</span>; <span class="comment">// 锁过期时间，单位毫秒</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> RedisTemplate&lt;String, String&gt; redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">RedisDistributedLock</span><span class="params">(RedisTemplate&lt;String, String&gt; redisTemplate)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.redisTemplate = redisTemplate;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">acquireLock</span><span class="params">()</span> &#123;</span><br><span class="line">        ValueOperations&lt;String, String&gt; valueOperations = redisTemplate.opsForValue();</span><br><span class="line">        <span class="comment">// 尝试获取分布式锁</span></span><br><span class="line">        <span class="type">Boolean</span> <span class="variable">result</span> <span class="operator">=</span> valueOperations.setIfAbsent(LOCK_KEY, <span class="string">&quot;locked&quot;</span>); <span class="comment">// RedisTemplate 的 setIfAbsent 方法，如果键不存在则设置键值对并返回 true，否则返回 false</span></span><br><span class="line">        <span class="keyword">if</span> (result != <span class="literal">null</span> &amp;&amp; result) &#123;</span><br><span class="line">            <span class="comment">// 成功获取到锁，设置锁的过期时间</span></span><br><span class="line">            redisTemplate.expire(LOCK_KEY, LOCK_EXPIRE_TIME, TimeUnit.MILLISECONDS); <span class="comment">// 设置键的过期时间，单位毫秒</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">releaseLock</span><span class="params">()</span> &#123;</span><br><span class="line">        redisTemplate.delete(LOCK_KEY); <span class="comment">// 删除键</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用分布式锁的业务逻辑</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doBusinessWithLock</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (acquireLock()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 获得分布式锁后执行业务逻辑</span></span><br><span class="line">                System.out.println(<span class="string">&quot;Acquired lock, do business logic...&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">3000</span>); <span class="comment">// 模拟业务处理时间</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                releaseLock(); <span class="comment">// 业务处理完成后释放锁</span></span><br><span class="line">                System.out.println(<span class="string">&quot;Released lock.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 未获得分布式锁，执行其他逻辑</span></span><br><span class="line">            System.out.println(<span class="string">&quot;Failed to acquire lock, do other logic...&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 创建 RedisTemplate 实例并设置连接信息</span></span><br><span class="line">        RedisTemplate&lt;String, String&gt; redisTemplate = <span class="keyword">new</span> <span class="title class_">RedisTemplate</span>&lt;&gt;();</span><br><span class="line">        <span class="comment">// 设置 Redis 连接工厂、序列化方式等</span></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">        <span class="type">RedisDistributedLock</span> <span class="variable">distributedLock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RedisDistributedLock</span>(redisTemplate);</span><br><span class="line">        distributedLock.doBusinessWithLock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>竞争条件（Race Condition）：在多个客户端同时尝试获取锁时，可能会出现竞争条件，导致多个客户端都成功获得锁，从而引发并发访问资源的问题。</li>
<li>死锁（Deadlock）：如果某个持有锁的客户端在业务处理期间发生异常或崩溃，导致没有释放锁的操作，可能会出现死锁的情况，导致其他客户端无法获得锁。</li>
<li>锁过期（Lock Expiration）：为了避免死锁，通常会给锁设置过期时间，但如果业务处理时间较长，超过了锁的过期时间，可能会导致其他客户端误认为锁已经释放，从而引发并发访问资源的问题。</li>
<li>锁的重入性（Lock Reentrancy）：在某些场景下，同一个客户端可能需要多次获取同一个锁，例如嵌套的业务处理逻辑。如果分布式锁没有支持锁的重入性，可能会导致同一个客户端无法在业务处理期间重新获取锁，从而引发死锁或并发访问资源的问题。</li>
<li>性能开销（Performance Overhead）：使用分布式锁可能会增加系统的性能开销，例如频繁的锁获取和锁释放操作，以及锁的管理和维护。如果锁的使用不当，可能会影响系统的性能和响应时间。</li>
</ol>
<h3 id="如何避免误释放锁"><a href="#如何避免误释放锁" class="headerlink" title="如何避免误释放锁"></a>如何避免误释放锁</h3><p>为了防止误删其他锁，可以通过<code>key</code>对应的<code>value</code>来判断。为了保证操作的原子性（先比较<code>value</code>，再删除<code>key</code>），可以通过Lua脚本来执行。</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 释放锁时，先比较锁对应的 value 值是否相等，避免锁的误释放</span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<h3 id="如何实现锁续期"><a href="#如何实现锁续期" class="headerlink" title="如何实现锁续期"></a>如何实现锁续期</h3><p>在 Redis 中实现分布式锁时，续期（即锁的自动延期）是一个常见的需求，尤其是在锁的持有时间可能超过最初设定的过期时间时。常见的解决方案是使用一个后台线程（或定时任务）定期检查锁是否仍然被持有，如果是，则延长锁的过期时间。这种机制通常被称为“<strong>看门狗</strong>”（Watchdog）机制。</p>
<p>基于 Redis 的分布式锁续期的基本思路：</p>
<ol>
<li><strong>获取锁时设置过期时间</strong>：在获取锁时，通常会设置一个过期时间（例如30秒），以防止客户端崩溃导致锁无法释放。</li>
<li><strong>启动一个续期线程</strong>：当成功获取锁后，启动一个后台线程，该线程定期（例如，每隔过期时间的1&#x2F;3时间）去检查锁是否还存在，如果存在，则延长锁的过期时间。</li>
<li><strong>续期操作</strong>：续期操作实际上就是重新设置锁的过期时间。在Redis中，可以使用<code>PEXPIRE</code>命令（以毫秒为单位）或<code>EXPIRE</code>命令（以秒为单位）来重新设置过期时间。</li>
<li><strong>释放锁时停止续期</strong>：当业务逻辑执行完毕，释放锁的时候，需要同时停止续期线程，以避免不必要的续期操作。</li>
</ol>
<p>需要注意的是，续期操作必须保证原子性，即在检查锁是否仍然由当前客户端持有之后，再执行续期。可以使用Lua脚本来保证原子性。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取锁</span></span><br><span class="line"><span class="keyword">if</span> set lock_key my_random_value NX PX <span class="number">30000</span>:</span><br><span class="line">    <span class="comment">// 锁获取成功</span></span><br><span class="line">    <span class="comment">// 启动一个看门狗线程，每10秒执行一次续期</span></span><br><span class="line">    watchdog = <span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">        <span class="keyword">while</span> (lockIsHeld) &#123;</span><br><span class="line">            sleep(<span class="number">10000</span>); <span class="comment">// 10秒</span></span><br><span class="line">            <span class="comment">// 使用Lua脚本续期：如果锁的值还是my_random_value，则重新设置为30秒</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">script</span> <span class="operator">=</span> <span class="string">&quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then &quot;</span> +</span><br><span class="line">                           <span class="string">&quot;return redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[2]) &quot;</span> +</span><br><span class="line">                           <span class="string">&quot;else &quot;</span> +</span><br><span class="line">                           <span class="string">&quot;return 0 &quot;</span> +</span><br><span class="line">                           <span class="string">&quot;end&quot;</span>;</span><br><span class="line">            redis.eval(script, lock_key, my_random_value, <span class="number">30000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    watchdog.start();</span><br><span class="line">    <span class="comment">// 执行业务逻辑</span></span><br><span class="line">    doBusiness();</span><br><span class="line">    <span class="comment">// 释放锁</span></span><br><span class="line">    <span class="comment">// 先停止看门狗线程</span></span><br><span class="line">    lockIsHeld = <span class="literal">false</span>;</span><br><span class="line">    watchdog.join();</span><br><span class="line">    <span class="comment">// 然后释放锁，使用Lua脚本来保证原子性</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">releaseScript</span> <span class="operator">=</span> <span class="string">&quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then &quot;</span> +</span><br><span class="line">                           <span class="string">&quot;return redis.call(&#x27;del&#x27;, KEYS[1]) &quot;</span> +</span><br><span class="line">                           <span class="string">&quot;else &quot;</span> +</span><br><span class="line">                           <span class="string">&quot;return 0 &quot;</span> +</span><br><span class="line">                           <span class="string">&quot;end&quot;</span>;</span><br><span class="line">    redis.eval(releaseScript, lock_key, my_random_value);</span><br></pre></td></tr></table></figure>

<p>在实际应用中，可以使用一些成熟的库，例如Redisson，它已经内置了看门狗机制来自动续期。在Redisson中，获取锁后，它会启动一个定时任务来定期续期，直到锁被释放或持有锁的客户端宕机。</p>
<p>使用Redisson的示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">RedissonClient</span> <span class="variable">redisson</span> <span class="operator">=</span> Redisson.create(config);</span><br><span class="line"><span class="type">RLock</span> <span class="variable">lock</span> <span class="operator">=</span> redisson.getLock(<span class="string">&quot;myLock&quot;</span>);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 获取锁，并设置尝试加锁时间和锁自动释放时间，但是Redisson的看门狗机制会在获取锁成功后自动续期</span></span><br><span class="line">    lock.lock(); <span class="comment">// 默认情况下，看门狗会每30/3=10秒续期一次，将锁的过期时间重置为30秒</span></span><br><span class="line">    <span class="comment">// 执行业务逻辑</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    lock.unlock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><h3 id="在-Redis-中绑定-CPU-核"><a href="#在-Redis-中绑定-CPU-核" class="headerlink" title="在 Redis 中绑定 CPU 核"></a>在 Redis 中绑定 CPU 核</h3><p>在 Redis 中绑定 CPU 核（CPU 亲和性）可以通过以下方法实现，以优化性能并减少上下文切换。以下是详细步骤：</p>
<p><strong>方法 1：通过 Redis 配置文件绑定</strong></p>
<p>Redis 从 <strong>6.0 版本</strong>开始支持 <code>server_cpulist</code> 配置项，可直接在配置文件中指定 CPU 核。</p>
<ol>
<li><p><strong>修改 <code>redis.conf</code> 文件</strong>：</p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 绑定 Redis 到 CPU 核心 0 和 1（逗号分隔）</span><br><span class="line">server_cpulist 0-1</span><br></pre></td></tr></table></figure>

<ul>
<li>格式支持：<code>0</code>（单个核心）、<code>0-3</code>（范围）、<code>0,2,4</code>（逗号分隔列表）。</li>
</ul>
</li>
<li><p><strong>重启 Redis 生效</strong>：</p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server /path/to/redis.conf</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>方法 2：使用 <code>taskset</code> 命令绑定</strong></p>
<p>通过 Linux 的 <code>taskset</code> 工具直接绑定 Redis 进程到指定 CPU 核。</p>
<ol>
<li><p><strong>启动 Redis 时绑定</strong>：</p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskset -c 0,1 ./redis-server /path/to/redis.conf</span><br></pre></td></tr></table></figure>

<ul>
<li><code>-c 0,1</code> 表示绑定到核心 0 和 1。</li>
</ul>
</li>
<li><p><strong>对已运行的 Redis 进程绑定</strong>：</p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskset -cp 0,1 &lt;redis_pid&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>方法 3：通过 Systemd 服务绑定</strong></p>
<p>如果 Redis 以 Systemd 服务运行，可在服务文件中添加 <code>CPUAffinity</code> 配置。</p>
<ol>
<li><p><strong>编辑 Redis 的 systemd 服务文件</strong>：</p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl edit redis.service</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>添加 CPU 亲和性配置</strong>：</p>
<p>ini</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">CPUAffinity=0 1</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>重启服务生效</strong>：</p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart redis</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>方法 4：使用 Cgroups (高级)</strong></p>
<p>通过 Linux 控制组 (<code>cgroups</code>) 精细化控制 CPU 资源。</p>
<ol>
<li><p><strong>创建 cgroup</strong>：</p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cgcreate -g cpuset:redis</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>分配 CPU 核心和内存节点</strong>：</p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 0-1 &gt; /sys/fs/cgroup/cpuset/redis/cpuset.cpus</span><br><span class="line">echo 0 &gt; /sys/fs/cgroup/cpuset/redis/cpuset.mems</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>启动 Redis 并加入 cgroup</strong>：</p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cgexec -g cpuset:redis ./redis-server /path/to/redis.conf</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>验证绑定是否生效</strong></p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 查看 Redis 进程 PID</span><br><span class="line">ps -ef | grep redis-server</span><br><span class="line"></span><br><span class="line"># 检查进程的 CPU 亲和性</span><br><span class="line">taskset -cp &lt;redis_pid&gt;</span><br><span class="line"></span><br><span class="line"># 或查看 /proc 文件系统</span><br><span class="line">cat /proc/&lt;redis_pid&gt;/status | grep Cpus_allowed</span><br></pre></td></tr></table></figure>

<p><strong>注意事项</strong></p>
<ol>
<li><p><strong>NUMA 架构</strong>：若服务器有多个 CPU 插槽，建议配合 <code>numactl</code> 工具绑定内存节点。</p>
<p>bash</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numactl --cpunodebind=0 --membind=0 ./redis-server</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>性能测试</strong>：绑定 CPU 可能提升缓存命中率，但需根据实际负载测试效果。</p>
</li>
<li><p><strong>超线程</strong>：物理核与逻辑核（如 <code>0</code> 和 <code>4</code> 可能是同一物理核的超线程）需区分，避免误绑。</p>
</li>
</ol>
<hr>
<p>通过上述方法，可有效将 Redis 实例绑定到指定 CPU 核，优化性能并减少资源争用。</p>
<h1 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h1><h2 id="Elasticsearch-的核心概念"><a href="#Elasticsearch-的核心概念" class="headerlink" title="Elasticsearch 的核心概念"></a><strong>Elasticsearch 的核心概念</strong></h2><ul>
<li><strong>文档：</strong> 数据的基本单位，通常是 JSON 格式。相当于数据库中的一行记录。</li>
<li><strong>索引：</strong> 具有相似特征的文档集合。相当于数据库中的一个表。一个索引对应一个或多个分片。</li>
<li><strong>类型：</strong> (7.x 之前) 索引内部的逻辑分区，允许在同一索引中存储不同类型的文档（如 <code>user</code>, <code>product</code>）。(<strong>注意：</strong> 在 7.x 中类型被废弃，8.x 中完全移除。现在一个索引通常只包含一种文档类型)。</li>
<li><strong>分片：</strong> 索引被水平分割成的子集。每个分片本身就是一个功能完整且独立的“索引”。<ul>
<li><strong>主分片：</strong> 存储文档数据和处理索引&#x2F;更新操作。索引创建时指定数量，后续不可更改（除非 Reindex）。</li>
<li><strong>副本分片：</strong> 主分片的拷贝。提供高可用性（主分片故障时副本可提升为主）和读取吞吐量（查询可负载均衡到所有副本）。</li>
</ul>
</li>
<li><strong>节点：</strong> 运行中的 Elasticsearch 实例。</li>
<li><strong>集群：</strong> 一个或多个节点协同工作的集合，共同持有整个数据并提供联合索引和搜索能力。</li>
<li><strong>倒排索引：</strong> ES 实现快速全文搜索的核心数据结构。它存储了词项（Token）到包含该词项的文档 ID 列表的映射。相比传统数据库的正排索引（文档 ID 到字段值），它更擅长回答“哪些文档包含某个词？”的问题。</li>
</ul>
<h2 id="什么是倒排索引？为什么它对搜索很重要？"><a href="#什么是倒排索引？为什么它对搜索很重要？" class="headerlink" title="什么是倒排索引？为什么它对搜索很重要？"></a><strong>什么是倒排索引？为什么它对搜索很重要？</strong></h2><ul>
<li><strong>定义：</strong> 倒排索引是一种将文档中的词项（Token）映射到包含该词项的文档列表的数据结构。它包含两个核心部分：<ul>
<li><strong>词项字典：</strong> 包含所有不重复的词项（Token），通常按字典序排序。</li>
<li><strong>倒排列表：</strong> 对于每个词项，记录包含该词项的所有文档 ID 列表（Postings List），以及词项在文档中出现的位置（Position）、频率（Term Frequency）等信息（用于相关性评分）。</li>
</ul>
</li>
<li><strong>重要性：</strong><ul>
<li><strong>快速定位：</strong> 直接通过词项找到包含它的文档，避免了扫描所有文档。</li>
<li><strong>高效布尔查询：</strong> AND&#x2F;OR&#x2F;NOT 操作可以通过对倒排列表进行交&#x2F;并&#x2F;差集运算高效完成。</li>
<li><strong>相关性评分基础：</strong> TF-IDF、BM25 等经典评分模型严重依赖倒排索引中存储的词频（TF）、文档频率（DF&#x2F;IDF）信息。</li>
<li><strong>支持短语查询：</strong> 利用存储的位置信息，可以精确查找相邻出现的词组。</li>
</ul>
</li>
</ul>
<h2 id="分片（Shard）和副本（Replica）是什么"><a href="#分片（Shard）和副本（Replica）是什么" class="headerlink" title="分片（Shard）和副本（Replica）是什么"></a>分片（Shard）和副本（Replica）是什么</h2><p>分片是索引的物理组成部分（一个 Lucene 索引），用于<strong>水平分割数据</strong>，使索引可以分布在多个节点上，实现<strong>水平扩展和并行处理</strong>。</p>
<p>副本是主分片的完整拷贝，作用是<strong>提供高可用性</strong>（主分片故障时副本可接管）和<strong>提高查询吞吐量&#x2F;性能</strong>（查询可以在副本上执行，分担负载）。主分片数量在索引创建时指定且后续不可变，副本数量可以动态调整。</p>
<h2 id="Elasticsearch-如何保证写入数据的可靠性？"><a href="#Elasticsearch-如何保证写入数据的可靠性？" class="headerlink" title="Elasticsearch 如何保证写入数据的可靠性？"></a>Elasticsearch 如何保证写入数据的可靠性？</h2><ul>
<li><strong>事务日志：</strong> 所有写入操作在写入内存缓冲区（In-memory Buffer）的同时，会立即追加写入到事务日志（Translog）中。Translog 是持久化的。</li>
<li><strong>Refresh：</strong> 定期（默认 1 秒）将内存缓冲区中的内容生成一个新的、可搜索的 Lucene 段（Segment），并清空缓冲区。这个过程使新写入的数据对搜索可见。<strong>注意：</strong> 此时数据还在操作系统的文件系统缓存（Page Cache）中，并未物理刷盘（<code>fsync</code>）。</li>
<li><strong>Flush：</strong> 定期（默认 30 分钟，或 Translog 大小达到阈值）执行以下操作：<ol>
<li>触发一次 Refresh，将所有在内存缓冲区中的数据生成新的段。</li>
<li>将文件系统缓存中的段数据物理 <code>fsync</code> 到磁盘。</li>
<li>清空（截断）旧的、已持久化的 Translog。</li>
</ol>
</li>
<li><strong>副本机制：</strong> 写入操作在主分片执行成功后，必须等待所有配置的副本分片也写入成功才返回客户端确认（除非使用 <code>wait_for_active_shards</code> 降低要求）。这确保了数据冗余。</li>
<li><strong>故障恢复：</strong> 节点重启时，会重放 Translog 中尚未刷盘的操作来恢复数据。副本分片的存在保证了主分片丢失时数据不丢。</li>
</ul>
<h2 id="解释一下-Elasticsearch-中的-refresh-和-flush-操作的区别"><a href="#解释一下-Elasticsearch-中的-refresh-和-flush-操作的区别" class="headerlink" title="解释一下 Elasticsearch 中的 refresh 和 flush 操作的区别"></a>解释一下 Elasticsearch 中的 <code>refresh</code> 和 <code>flush</code> 操作的区别</h2><ul>
<li><strong><code>refresh</code>：</strong><ul>
<li><strong>目的：</strong> 使新写入的数据对搜索可见。</li>
<li><strong>操作：</strong> 将内存缓冲区中的文档生成新的、可搜索的 Lucene 段（Segment）。段写入文件系统缓存（Page Cache），<strong>不</strong>立即 <code>fsync</code> 到磁盘。</li>
<li><strong>频率：</strong> 默认每秒一次（可通过 <code>index.refresh_interval</code> 配置）。</li>
<li><strong>开销：</strong> 相对较低，因为只写入 Page Cache。频繁 Refresh 会产生大量小段，增加合并（Merge）压力。</li>
</ul>
</li>
<li><strong><code>flush</code>：</strong><ul>
<li><strong>目的：</strong> 将文件系统缓存中的数据安全持久化到磁盘，并清理 Translog。</li>
<li><strong>操作：</strong><ol>
<li>执行一次 Refresh（确保所有数据都在段里）。</li>
<li>调用 <code>fsync</code> 将文件系统缓存中的所有段数据强制写入磁盘存储设备。</li>
<li>清空（截断）当前 Translog（因为数据已安全落盘）。</li>
</ol>
</li>
<li><strong>触发条件：</strong><ul>
<li>定时（默认 30 分钟，<code>index.translog.sync_interval</code> &#x2F; <code>index.translog.durability</code>）。</li>
<li>Translog 大小达到阈值（默认 512MB，<code>index.translog.flush_threshold_size</code>）。</li>
<li>显式调用 <code>_flush</code> API。</li>
</ul>
</li>
<li><strong>开销：</strong> 相对较高，因为涉及磁盘 I&#x2F;O (<code>fsync</code>)。</li>
</ul>
</li>
</ul>
<h2 id="集群状态-Yellow-或-Red-意味着什么？如何排查"><a href="#集群状态-Yellow-或-Red-意味着什么？如何排查" class="headerlink" title="集群状态 Yellow 或 Red 意味着什么？如何排查?"></a>集群状态 Yellow 或 Red 意味着什么？如何排查?</h2><ul>
<li><strong>Yellow：</strong><ul>
<li><strong>含义：</strong> 所有主分片都已分配，但<strong>至少有一个副本分片没有分配</strong>。</li>
<li><strong>常见原因：</strong><ul>
<li>节点数量不足（例如，索引配置了 <code>number_of_replicas=1</code>，但集群只有一个节点）。</li>
<li>新创建的索引副本分片正在初始化（短暂状态）。</li>
<li>有节点故障，导致部分副本分片丢失（但主分片还在）。</li>
</ul>
</li>
<li><strong>影响：</strong> 高可用性降低（丢失一个节点可能导致数据丢失&#x2F;不可用），查询吞吐量可能下降（副本少）。</li>
<li><strong>排查：</strong> <code>GET _cluster/allocation/explain</code> API 查看未分配分片的具体原因；检查节点数、节点状态、磁盘空间、分片分配设置。</li>
</ul>
</li>
<li><strong>Red：</strong><ul>
<li><strong>含义：</strong> <strong>至少有一个主分片没有分配</strong>（可能连带其副本也缺失）。</li>
<li><strong>常见原因：</strong><ul>
<li>持有主分片的节点永久丢失，且没有可用的副本分片可以提升为主分片。</li>
<li>磁盘空间不足导致分片无法分配。</li>
<li>配置错误（如分片分配规则 exclude 了所有节点）。</li>
</ul>
</li>
<li><strong>影响：</strong> <strong>数据部分丢失或完全不可用！</strong> 涉及该主分片的索引和搜索操作都会失败。</li>
<li><strong>排查：</strong> 紧急！立即检查 <code>_cluster/health</code> 和 <code>_cat/shards?v</code> 确认哪些索引&#x2F;分片是 <code>red</code>。使用 <code>GET _cluster/allocation/explain</code> 分析未分配原因。检查节点状态、磁盘空间、日志。可能需要从备份恢复或手动分配分片（风险操作）。</li>
</ul>
</li>
<li><strong>目标：</strong> 始终追求 <code>Green</code> 状态。</li>
</ul>
<h2 id="解释一下什么是脑裂（Split-Brain）问题？Elasticsearch-如何防止脑裂？"><a href="#解释一下什么是脑裂（Split-Brain）问题？Elasticsearch-如何防止脑裂？" class="headerlink" title="解释一下什么是脑裂（Split-Brain）问题？Elasticsearch 如何防止脑裂？"></a>解释一下什么是脑裂（Split-Brain）问题？Elasticsearch 如何防止脑裂？</h2><ul>
<li><strong>定义：</strong> 在分布式系统中，当网络分区（Network Partition）发生时，集群的不同部分（节点组）可能无法互相通信。如果每个部分都认为自己是唯一可用的部分并选举出新的主节点，就会导致集群分裂成两个或多个独立运作的“脑”，各自接受写入操作，造成<strong>数据不一致</strong>和<strong>冲突</strong>。</li>
<li><strong>ES 防止机制：</strong> 主要通过 <strong><code>discovery.zen.minimum_master_nodes</code></strong> 设置（在 7.x 之前显式配置）或 <strong><code>cluster.initial_master_nodes</code></strong> + <strong>Quorum</strong> 机制（7.x+ 尤其是基于 Raft 的选举）：<ul>
<li><strong>核心思想：</strong> 确保只有拥有<strong>多数</strong>（Quorum, &gt; N&#x2F;2）<strong>主节点资格节点</strong>的节点组才能成功选举主节点或维持主节点。假设有 <code>N</code> 个主节点资格节点：<ul>
<li>设置 <code>discovery.zen.minimum_master_nodes = (N/2) + 1</code> （例如，3节点集群设为2）。</li>
<li>在 7.x+ 中，使用 <code>cluster.initial_master_nodes</code> 列出初始主节点，新选举协议自动确保需要多数投票。</li>
</ul>
</li>
<li><strong>效果：</strong> 在网络分区时，任何节点组如果包含的主节点资格节点数不足多数（&lt;&#x3D; N&#x2F;2），就无法选举新主节点或维持现有主节点状态（因为它无法获得多数确认），从而<strong>无法提供服务或接受写操作</strong>，避免了“双主”导致的脑裂。只有拥有多数节点的分区才能正常运作。</li>
</ul>
</li>
</ul>
<h2 id="什么是映射爆炸？如何避免？"><a href="#什么是映射爆炸？如何避免？" class="headerlink" title="什么是映射爆炸？如何避免？"></a>什么是映射爆炸？如何避免？</h2><ul>
<li><strong>定义：</strong> 当索引中包含大量<strong>唯一</strong>字段（通常是动态映射产生的）时，导致集群状态（Cluster State）变得极其庞大（可能超过数百MB甚至GB），主节点在广播和维持集群状态时压力巨大，严重影响集群稳定性和性能。</li>
<li><strong>原因：</strong> 常见于索引了类似日志数据，其中每个文档都有大量不同的、不可预测的字段（如包含用户ID或请求ID的字段名）。</li>
<li><strong>避免：</strong><ul>
<li><strong>严格控制动态映射：</strong> 设置 <code>&quot;dynamic&quot;: &quot;strict&quot;</code>（禁止未知字段）或 <code>&quot;dynamic&quot;: &quot;false&quot;</code>（忽略未知字段，但不索引）。优先使用<strong>显式映射</strong>。</li>
<li><strong>使用 <code>flattened</code> 类型：</strong> 将整个 JSON 对象映射为单个 <code>flattened</code> 字段，避免为每个内部键创建独立字段。适用于不需要独立查询&#x2F;聚合的元数据。</li>
<li><strong>使用 <code>object</code>&#x2F;<code>nested</code> 但限制深度：</strong> 使用 <code>index.mapping.depth.limit</code> 控制嵌套深度。</li>
<li><strong>字段别名：</strong> 如果不同来源的字段语义相同，用别名统一映射到一个字段。</li>
<li><strong>合理的索引设计：</strong> 避免将差异巨大的文档类型塞进同一个索引。</li>
</ul>
</li>
</ul>
<h2 id="什么情况下你会考虑使用-keyword-类型而不是-text-类型？"><a href="#什么情况下你会考虑使用-keyword-类型而不是-text-类型？" class="headerlink" title="什么情况下你会考虑使用 keyword 类型而不是 text 类型？"></a>什么情况下你会考虑使用 <code>keyword</code> 类型而不是 <code>text</code> 类型？</h2><ul>
<li>使用 <code>keyword</code> 类型当：<ul>
<li>需要<strong>精确匹配</strong>（e.g., 状态码、标签、ID、枚举值）。</li>
<li>需要<strong>聚合</strong>（Aggregations - Terms, Significant Terms）。</li>
<li>需要<strong>排序</strong>（Sorting）。</li>
<li>不需要全文分词搜索。</li>
</ul>
</li>
<li>使用 <code>text</code> 类型当：<ul>
<li>字段内容是需要被<strong>全文搜索</strong>的自然语言文本（e.g., 邮件正文、产品描述）。</li>
<li>需要被<strong>分词器</strong>处理（Tokenization, Normalization）。</li>
</ul>
</li>
<li><strong>注意：</strong> 通常对同一个字段会同时定义 <code>text</code>（用于搜索）和 <code>keyword</code>（用于聚合&#x2F;排序）多字段（Multi-fields）。</li>
</ul>
<h2 id="为什么需要段合并（Segment-Merging）？它有什么优缺点？"><a href="#为什么需要段合并（Segment-Merging）？它有什么优缺点？" class="headerlink" title="为什么需要段合并（Segment Merging）？它有什么优缺点？"></a>为什么需要段合并（Segment Merging）？它有什么优缺点？</h2><ul>
<li><strong>为什么需要：</strong> 频繁的 refresh 会产生大量小的 Lucene 段。小段过多会降低查询性能（需要打开更多文件句柄）且占用更多资源（文件描述符、内存）。删除操作只是标记文档为删除，空间不会立即释放。</li>
<li><strong>优点：</strong><ul>
<li>减少段数量，<strong>提升查询速度</strong>（减少文件打开和搜索范围）。</li>
<li><strong>真正删除</strong>被标记删除的文档，<strong>回收磁盘空间</strong>。</li>
<li>合并过程中优化索引结构（如压缩）。</li>
</ul>
</li>
<li><strong>缺点：</strong><ul>
<li>是 <strong>I&#x2F;O 和 CPU 密集型操作</strong>，在合并期间可能<strong>显著影响集群性能</strong>（写入延迟、查询延迟增加）。</li>
<li>需要额外的临时磁盘空间。</li>
</ul>
</li>
</ul>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">
    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/post/7992e236.html" rel="prev" title="学习&面试-Java">
                  <i class="fa fa-angle-left"></i> 学习&面试-Java
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/post/688e2513.html" rel="next" title="学习&面试-消息队列">
                  学习&面试-消息队列 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa-regular fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder"></span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Word count total">110k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">6:38</span>
  </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.9.0/mermaid.min.js","integrity":"sha256-stuqcu2FrjYCXDOytWFA5SoUE/r3nkp6gTglzNSlavU="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>

  <script class="next-config" data-name="wavedrom" type="application/json">{"enable":true,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/wavedrom/3.5.0/wavedrom.min.js","integrity":"sha256-INLAoJc6quTNfiMWkGZniYO2cxE8mHpddnLow1m6RFs="}}</script>
  <script class="next-config" data-name="wavedrom_skin" type="application/json">{"enable":true,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/wavedrom/3.5.0/skins/default.js","integrity":"sha256-fduc/Zszk5ezWws2uInY/ALWVmIrmV6VTgXbsYSReFI="}}</script>
  <script src="/js/third-party/tags/wavedrom.js"></script>




  





</body>
</html>
